{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a4ff38",
   "metadata": {},
   "source": [
    "### `Experiment: 02`\n",
    "\n",
    "> for each data directory `[]`:\n",
    "\n",
    "#### *Data Loading and Augmentation*\n",
    "> Keeps separate <span style=\"color: red\">20%</span> per class test data, chosen <span style=\"color: red\">randomly</span> with train_test_split which is unseen for both the pretext and the validation task\n",
    "\n",
    "> augment data for the pretext task with  <span style=\"color: red\">4 labels: [0->0, 90->1, 180->2, 270->3]</span> \n",
    "\n",
    "#### *Pretext Task*\n",
    "\n",
    "> for each architecture in <span style=\"color: red\">['cnn', 'resnet50', 'resnet101', 'resnet152', 'efficientnetb0', 'vgg16', 'vgg19', 'inceptionv3', 'unet']</span> \n",
    ">\n",
    "> trains the data on the defined pretext models with the following configurations:\n",
    ">   - build_custom_cnn_model\n",
    ">       - <span style=\"color: red\"> input_shape=(128, 128, 1)</span><br/>\n",
    ">       - <span style=\"color: red\"> num_classes=4</span><br/>\n",
    ">       - architecture_name=architecture_name<br/>\n",
    ">       - <span style=\"color: red\"> fine_tune=True</span><br/>\n",
    ">\n",
    ">\n",
    "> ### CNN\n",
    "> - input shape: (<span style=\"color: red\">128</span>, <span style=\"color: red\">128</span>, 1)\n",
    "> - Conv1: \n",
    ">     - Conv2D(<span style=\"color: red\">32</span>, <span style=\"color: red\">(3, 3)</span>)\n",
    ">     - BatchNormalization\n",
    ">     - MaxPooling2D(<span style=\"color: red\">(2, 2)</span>)\n",
    "> - Conv2: \n",
    ">     - Conv2D(<span style=\"color: red\">64</span>, <span style=\"color: red\">(3, 3)</span>)\n",
    ">     - BatchNormalization\n",
    ">     - MaxPooling2D(<span style=\"color: red\">(2, 2)</span>)\n",
    "> - Conv3: \n",
    ">     - Conv2D(<span style=\"color: red\">128</span>, <span style=\"color: red\">(3, 3)</span>)\n",
    ">     - BatchNormalization\n",
    ">     - MaxPooling2D(<span style=\"color: red\">(2, 2)</span>)\n",
    "> - Conv4: \n",
    ">     - Conv2D(<span style=\"color: red\">256</span>, <span style=\"color: red\">(3, 3)</span>)\n",
    ">     - BatchNormalization\n",
    ">     - GlobalAveragePooling2D()\n",
    "> - Dense(<span style=\"color: red\">512</span>, activation=<span style=\"color: red\">'relu'</span>)\n",
    "> - Dropout(<span style=\"color: red\">0.5</span>)\n",
    "> - output: Dense(num_classes=4, activation=<span style=\"color: red\">'softmax'</span>)\n",
    "> - Training Configuration:\n",
    ">     - optimizer=tf.keras.optimizers.Adam(learning_rate=<span style=\"color: red\">0.001</span>)\n",
    ">     - loss=<span style=\"color: red\">'sparse_categorical_crossentropy'</span>\n",
    ">     - metrics=['accuracy']\n",
    ">\n",
    "> ### Transfer Learning Models\n",
    "> ### *'resnet50', 'resnet101', 'resnet152', 'efficientnetb0', 'vgg16', 'vgg19'*\n",
    "> - input shape: (<span style=\"color: red\">128</span>, <span style=\"color: red\">128</span>, 1)\n",
    "> - Channel Conversion: layers.Conv2D(<span style=\"color: red\">3</span>, <span style=\"color: red\">(1, 1)</span>) [to make 3 channels]\n",
    "> - Base Model Configuration:\n",
    ">     - weights=<span style=\"color: red\">'imagenet'</span>\n",
    ">     - include_top=False\n",
    ">     - input_shape=(<span style=\"color: red\">128</span>, <span style=\"color: red\">128</span>, 3)\n",
    "> - GlobalAveragePooling2D()\n",
    "> - output: Dense(num_classes=4, activation=<span style=\"color: red\">'softmax'</span>)\n",
    "> - Training Configuration:\n",
    ">     - optimizer=tf.keras.optimizers.Adam(learning_rate=<span style=\"color: red\">0.001</span>)\n",
    ">     - loss=<span style=\"color: red\">'sparse_categorical_crossentropy'</span>\n",
    ">     - metrics=['accuracy']\n",
    ">\n",
    "> ### *'inceptionv3'*\n",
    "> - Special Input Handling:\n",
    ">     - if input shape < <span style=\"color: red\">75</span>: upsample to (<span style=\"color: red\">75</span>, <span style=\"color: red\">75</span>)\n",
    "> - Rest of configuration same as transfer learning models for (<span style=\"color: red\">128</span>, <span style=\"color: red\">128</span>) case\n",
    ">\n",
    "> #### U-Net Architecture\n",
    "> ##### Input Layer\n",
    "> - Input shape: (<span style=\"color: red\">128</span>, <span style=\"color: red\">128</span>, 3)\n",
    ">\n",
    "> ##### Encoding Path\n",
    "> - Conv2D Layer 1:\n",
    ">     - filters=<span style=\"color: red\">64</span>\n",
    ">     - kernel_size=<span style=\"color: red\">(3, 3)</span>\n",
    ">     - activation=<span style=\"color: red\">'relu'</span>\n",
    ">     - padding='same'\n",
    "> - MaxPooling2D: pool_size=<span style=\"color: red\">(2, 2)</span>\n",
    ">\n",
    "> - Conv2D Layer 2:\n",
    ">     - filters=<span style=\"color: red\">128</span>\n",
    ">     - kernel_size=<span style=\"color: red\">(3, 3)</span>\n",
    ">     - activation=<span style=\"color: red\">'relu'</span>\n",
    ">     - padding='same'\n",
    "> - MaxPooling2D: pool_size=<span style=\"color: red\">(2, 2)</span>\n",
    ">\n",
    "> ##### Bridge\n",
    "> - Conv2D Layer:\n",
    ">     - filters=<span style=\"color: red\">256</span>\n",
    ">     - kernel_size=<span style=\"color: red\">(3, 3)</span>\n",
    ">     - activation=<span style=\"color: red\">'relu'</span>\n",
    ">     - padding='same'\n",
    ">\n",
    "> ##### Decoding Path\n",
    "> - UpSampling2D: size=<span style=\"color: red\">(2, 2)</span>\n",
    "> - Concatenate with Conv2D Layer 2 (128 filters)\n",
    "> - UpSampling2D: size=<span style=\"color: red\">(2, 2)</span>\n",
    "> - Concatenate with Conv2D Layer 1 (64 filters)\n",
    ">\n",
    "> ##### Output Layer\n",
    "> - Conv2D:\n",
    ">     - filters=3\n",
    ">     - kernel_size=<span style=\"color: red\">(1, 1)</span>\n",
    ">     - activation=<span style=\"color: red\">'softmax'</span>\n",
    "> ##### Training Configuration\n",
    "> - output: Dense(num_classes=4, activation=<span style=\"color: red\">'softmax'</span>)\n",
    "> - Training Configuration:\n",
    ">     - optimizer=tf.keras.optimizers.Adam(learning_rate=<span style=\"color: red\">0.001</span>)\n",
    ">     - loss=<span style=\"color: red\">'sparse_categorical_crossentropy'</span>\n",
    ">     - metrics=['accuracy']\n",
    "\n",
    "#### *Downstream Task*\n",
    "\n",
    "> #### Function: `evaluate_downstream_task(clf, X_test, y_test)`\n",
    "> \n",
    "> Evaluates the downstream task performance on held-out test set\n",
    "> \n",
    "> **Returns**: Dictionary containing:\n",
    "> - Accuracy\n",
    "> - Precision (macro average)\n",
    "> - Recall (macro average)\n",
    "> - F1-score (macro average)\n",
    "> - Confusion Matrix\n",
    ">\n",
    "> #### Function: `train_downstream_task(train_features, train_labels, test_features, test_labels, classifier, n_splits)`\n",
    ">\n",
    "> **Parameters:**\n",
    "> - classifier: <span style=\"color: red\">'random_forest'</span> | <span style=\"color: red\">'svm'</span> | <span style=\"color: red\">'gradient_boosting'</span> | <span style=\"color: red\">'xgboost'</span>\n",
    "> - n_splits: <span style=\"color: red\">5</span> (for cross-validation)\n",
    ">\n",
    "> **Classifier Configurations:**\n",
    ">\n",
    "> 1. Random Forest:\n",
    ">    - n_estimators: <span style=\"color: red\">100</span>\n",
    ">    - random_state: RANDOM_SEED\n",
    ">\n",
    "> 2. SVM:\n",
    ">    - kernel: <span style=\"color: red\">'linear'</span>\n",
    ">    - random_state: RANDOM_SEED\n",
    ">\n",
    "> 3. Gradient Boosting:\n",
    ">    - n_estimators: <span style=\"color: red\">100</span>\n",
    ">    - random_state: RANDOM_SEED\n",
    ">\n",
    "> 4. XGBoost:\n",
    ">    - n_estimators: <span style=\"color: red\">100</span>\n",
    ">    - random_state: RANDOM_SEED\n",
    ">    - use_label_encoder: True\n",
    ">\n",
    "> **Process Flow:**\n",
    "> 1. Cross-validation:\n",
    ">    - Strategy: StratifiedKFold\n",
    ">    - n_splits: <span style=\"color: red\">5</span>\n",
    ">    - shuffle: True\n",
    ">    - random_state: RANDOM_SEED\n",
    ">    - Computes: accuracy, precision, recall, f1 scores for each fold\n",
    ">\n",
    "> 2. Final Training:\n",
    ">    - Trains on full training data\n",
    ">\n",
    "> 3. Test Evaluation:\n",
    ">    - Evaluates final model on held-out test set\n",
    ">    - Uses `evaluate_downstream_task` function\n",
    ">    - Computes final metrics on test set\n",
    ">\n",
    "> **Returns:**\n",
    "> - Trained classifier\n",
    "> - Cross-validation scores (accuracy, precision, recall, f1)\n",
    "> - Test metrics dictionary from `evaluate_downstream_task`\n",
    ">\n",
    "> **Metrics Computed:**\n",
    "> - Accuracy\n",
    "> - Precision (macro)\n",
    "> - Recall (macro)\n",
    "> - F1-score (macro)\n",
    "> - Confusion Matrix (not for CV but for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948fba81-a549-4689-ae34-e8a64110131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 14:25:47.469913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-28 14:25:47.776228: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-28 14:25:47.785161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-28 14:25:47.785205: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-28 14:25:49.906450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-28 14:25:49.906549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-28 14:25:49.906558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./exp-02')\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import ResultsTracker\n",
    "from meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e282851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_random_seeds(seed=RANDOM_SEED):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c7aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(data_dir, img_size=(128, 128), color_mode='grayscale', test_size=0.2):\n",
    "    \"\"\"Load data and create a held-out test set stratified by class\"\"\"\n",
    "    images_by_class = {}\n",
    "    labels_by_class = {}\n",
    "    class_distribution = {}\n",
    "    \n",
    "    # Load images\n",
    "    class_folders = os.listdir(data_dir)\n",
    "    for class_index, class_folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(data_dir, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            images_by_class[class_index] = []\n",
    "            labels_by_class[class_index] = []\n",
    "            \n",
    "            for img_file in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                image = load_img(img_path, target_size=img_size, color_mode=color_mode)\n",
    "                image = img_to_array(image) / 255.0\n",
    "                images_by_class[class_index].append(image)\n",
    "                labels_by_class[class_index].append(class_index)\n",
    "    \n",
    "    # Split each class separately\n",
    "    train_images, train_labels = [], []\n",
    "    test_images, test_labels = [], []\n",
    "    \n",
    "    print(\"\\nData Distribution:\")\n",
    "    print(f\"{'Class':^10} {'Total':^10} {'Train':^10} {'Test':^10}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for class_idx in images_by_class:\n",
    "        X = np.array(images_by_class[class_idx])\n",
    "        y = np.array(labels_by_class[class_idx])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=RANDOM_SEED\n",
    "        ) # TODO, stratify=y\n",
    "        \n",
    "        train_images.extend(X_train)\n",
    "        train_labels.extend(y_train)\n",
    "        test_images.extend(X_test)\n",
    "        test_labels.extend(y_test)\n",
    "        \n",
    "        # Store distribution info\n",
    "        class_distribution[class_idx] = {\n",
    "            'total': len(X),\n",
    "            'train': len(X_train),\n",
    "            'test': len(X_test)\n",
    "        }\n",
    "        \n",
    "        print(f\"{class_idx:^10} {len(X):^10} {len(X_train):^10} {len(X_test):^10}\")\n",
    "    \n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    print(\"\\nSummary of Loaded Data:\")\n",
    "    print(f\"[DATAINFO] Total images: {len(train_images) + len(test_images)}\")\n",
    "    print(f\"[DATAINFO] Training set: {len(train_images)} images ({(1-test_size)*100:.0f}%)\")\n",
    "    print(f\"[DATAINFO] Test set: {len(test_images)} images ({test_size*100:.0f}%)\")\n",
    "    print(f\"[DATAINFO] Image shape: {train_images[0].shape}\")\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1cb5cef-d706-4b6d-9209-ff7728ef6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Augmentation with diverse transformations (Rotation, Brightness, Scaling, Translation, etc.)\n",
    "def augment_image(image, rotation_angle):\n",
    "    \"\"\"Apply a diverse set of augmentations to the image.\"\"\"\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)  # Flip horizontally\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)  # Brightness adjustment\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)  # Contrast adjustment\n",
    "    image = tf.image.random_zoom(image, (0.8, 1.2))  # Zooming simulation\n",
    "    image = tf.image.random_translation(image, translations=[5, 5])  # Random Translation\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)  # Saturation adjustment\n",
    "    image = tf.image.random_hue(image, max_delta=0.2)  # Hue adjustment\n",
    "    image = tf.image.random_jpeg_quality(image, min_jpeg_quality=50, max_jpeg_quality=100)  # JPEG quality jitter\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 70, 70)  # Zooming simulation via resizing\n",
    "    image = tf.image.random_crop(image, size=[64, 64, 1])  # Crop back to original size\n",
    "    '''\n",
    "    # Apply rotation (keeping the original logic)\n",
    "    # rotation_angle = np.random.choice([0, 90, 180, 270])\n",
    "    if rotation_angle == 90:\n",
    "        image = tf.image.rot90(image)\n",
    "    elif rotation_angle == 180:\n",
    "        image = tf.image.rot90(image, k=2)\n",
    "    elif rotation_angle == 270:\n",
    "        image = tf.image.rot90(image, k=3)\n",
    "\n",
    "    label = rotation_angle // 90\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19940af7-a03e-4898-8496-19af04a00367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images):\n",
    "    augmented_images = []\n",
    "    labels = []\n",
    "    for image in images:\n",
    "        for rotation_angle in [0, 90, 180, 270]:\n",
    "            aug_image, label = augment_image(image, rotation_angle)\n",
    "            augmented_images.append(aug_image)\n",
    "            labels.append(label)\n",
    "    print(f'> {len(augmented_images)} augmented images generated each of shape {augmented_images[0].shape} with {len(labels)} labels')\n",
    "    return np.array(augmented_images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b4d1442-2232-41ba-a0d3-783bb8b72db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Balanced Sampling using Oversampling (Copies data from minor class to balance number of samples)\n",
    "def balance_classes(x_data, y_data):\n",
    "    ros = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "    x_flattened = x_data.reshape((x_data.shape[0], -1))  # Reshape to 2D for balancing\n",
    "    x_resampled, y_resampled = ros.fit_resample(x_flattened, y_data)\n",
    "    x_resampled = x_resampled.reshape((-1, x_data.shape[1], x_data.shape[2], x_data.shape[3]))  # Reshape back to original\n",
    "    print(f'> (balancing) resampled to {x_resampled.shape[0]} samples')\n",
    "    return x_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b3bb16-e1ca-4536-a5da-ff206262dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to build U-Net (custom   implementation)\n",
    "def build_unet_model(input_shape=(128, 128, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoding (down-sampling) path\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bridge (bottom of the U-Net)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    \n",
    "    # Decoding (up-sampling) path\n",
    "    u1 = layers.UpSampling2D((2, 2))(c3)\n",
    "    u1 = layers.Concatenate()([u1, c2])\n",
    "    \n",
    "    u2 = layers.UpSampling2D((2, 2))(u1)\n",
    "    u2 = layers.Concatenate()([u2, c1])\n",
    "    \n",
    "    outputs = layers.Conv2D(3, (1, 1), activation='softmax')(u2)\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ad901c-996c-4e8d-a3d3-09d5f5bd6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn_model(input_shape=(128, 128, 1), num_classes=4, architecture_name=None, fine_tune=True):\n",
    "    print(f'> pretext task training model: input_shape {input_shape}, num_classes {num_classes}, architecture_name {architecture_name}')\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    if architecture_name != 'cnn':\n",
    "        # Upsample input to the required size if needed (InceptionV3 requires minimum 75x75)\n",
    "        if architecture_name == 'inceptionv3' and (input_shape[0] < 75 or input_shape[1] < 75):\n",
    "            required_size = (75, 75)  # InceptionV3 minimum size\n",
    "        else:\n",
    "            required_size = (input_shape[0], input_shape[1])  # Default size for other models\n",
    "            \n",
    "        x = layers.Resizing(required_size[0], required_size[1])(inputs)  # Resize input to required size\n",
    "\n",
    "        # Convert grayscale (1-channel) to 3-channel RGB for pretrained models\n",
    "        x = layers.Conv2D(3, (1, 1))(x)\n",
    "        \n",
    "        # Pretrained model selection logic\n",
    "        # ResNet Variants\n",
    "        if architecture_name == 'resnet50':\n",
    "            from tensorflow.keras.applications import ResNet50\n",
    "            base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        elif architecture_name == 'resnet101':\n",
    "            from tensorflow.keras.applications import ResNet101\n",
    "            base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        elif architecture_name == 'resnet152':\n",
    "            from tensorflow.keras.applications import ResNet152\n",
    "            base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        \n",
    "        # EfficientNetB0\n",
    "        elif architecture_name == 'efficientnetb0':\n",
    "            from tensorflow.keras.applications import EfficientNetB0\n",
    "            base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "\n",
    "        # VGGNet Variants\n",
    "        elif architecture_name == 'vgg16':\n",
    "            from tensorflow.keras.applications import VGG16\n",
    "            base_model = VGG16(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        elif architecture_name == 'vgg19':\n",
    "            from tensorflow.keras.applications import VGG19\n",
    "            base_model = VGG19(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "\n",
    "        # InceptionV3\n",
    "        elif architecture_name == 'inceptionv3':\n",
    "            from tensorflow.keras.applications import InceptionV3\n",
    "            base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "\n",
    "        # U-Net (not from Keras applications, custom U-Net function)\n",
    "        elif architecture_name == 'unet':\n",
    "            base_model = build_unet_model(input_shape=(required_size[0], required_size[1], 3))  # Custom function to build U-Net model\n",
    "\n",
    "        # Set base model to non-trainable if fine-tuning is disabled\n",
    "        if not fine_tune:\n",
    "            base_model.trainable = False\n",
    "        else:\n",
    "            base_model.trainable = True\n",
    "        \n",
    "        # Apply base model to input\n",
    "        x = base_model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    else:\n",
    "        # Build a custom CNN if no pretrained model is specified\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary(line_length=120, expand_nested=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "639157d6-c601-4978-b38a-06a70007612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each model name and build the model\n",
    "# for model_name in architecture_names:\n",
    "#     print(f\"\\nBuilding model: {model_name}\")\n",
    "#     model = build_custom_cnn_model(input_shape=(128, 128, 1), num_classes=4, architecture_name=model_name, fine_tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54989ec3-1ee7-43e9-b368-969c1e291b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the trained model\n",
    "def save_model(model, architecture_name, data_dir):\n",
    "    model_name = f\"pretext_model_{data_dir.split('/')[-2]}_{data_dir.split('/')[-1]}_{architecture_name}.h5\"\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    model_path = os.path.join(MODEL_DIR, model_name)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Check if the file exists after saving\n",
    "    if os.path.isfile(model_path):\n",
    "        print(f\"> Model successfully saved as {model_path}\")\n",
    "    else:\n",
    "        print(\"> ERROR: Model file not found after saving.\")\n",
    "\n",
    "# Function to load the saved model\n",
    "def load_model(architecture_name, data_dir):\n",
    "    model_name = f\"pretext_model_{data_dir.split('/')[-2]}_{data_dir.split('/')[-1]}_{architecture_name}.h5\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_name)\n",
    "    \n",
    "    # Check if the file exists before loading\n",
    "    if os.path.isfile(model_path):\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"Model successfully loaded from {model_path}\")\n",
    "        \n",
    "        # Sanity check: test with a small batch of random data\n",
    "        random_input = np.random.rand(1, 128, 128, 1)  # Adjust the input shape as per your model requirements\n",
    "        try:\n",
    "            prediction = model.predict(random_input)\n",
    "            # print(\"Sanity check passed: Model loaded and successfully made predictions.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Sanity check failed: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Error: Model file not found. Load operation failed.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60b8a1d-d056-459b-b6fa-cf1453ded309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Extraction from deeper layers\n",
    "def extract_features(pretext_model, x_data, layer_index=-2):\n",
    "    intermediate_model = models.Model(inputs=pretext_model.input, outputs=pretext_model.layers[layer_index].output)\n",
    "    # print('> intermediate feature extractor model:')\n",
    "    # intermediate_model.summary()\n",
    "    features = intermediate_model.predict(x_data)\n",
    "    print(f'> extracted features of shape {features.shape}')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c7ca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_downstream_task(clf, X_test, y_test):\n",
    "    \"\"\"Evaluate the downstream task on the held-out test set\"\"\"\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48546cc-0530-4cc7-b97e-4a892c5d79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_downstream_task(train_features, train_labels, test_features, test_labels, classifier='random_forest', n_splits=5):\n",
    "    \"\"\"Modified to include validation during training and final evaluation on test set\"\"\"\n",
    "    print(f'> performing downstream task with {classifier}')\n",
    "    \n",
    "    if classifier == 'random_forest':\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "    elif classifier == 'svm':\n",
    "        clf = SVC(kernel='linear', random_state=RANDOM_SEED)\n",
    "    elif classifier == 'gradient_boosting':\n",
    "        clf = GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_SEED)\n",
    "    elif classifier == 'xgboost':\n",
    "        clf = XGBClassifier(n_estimators=100, random_state=RANDOM_SEED, use_label_encoder=True)\n",
    "\n",
    "    # First, perform cross-validation on training data\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    cv_scores = {\n",
    "        'accuracies': [], 'precisions': [], 'recalls': [], 'f1_scores': []\n",
    "    }\n",
    "    \n",
    "    # print(\"\\nCross-validation results:\")\n",
    "    for train_idx, val_idx in skf.split(train_features, train_labels):\n",
    "        X_train_fold, X_val_fold = train_features[train_idx], train_features[val_idx]\n",
    "        y_train_fold, y_val_fold = train_labels[train_idx], train_labels[val_idx]\n",
    "        \n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = clf.predict(X_val_fold)\n",
    "        \n",
    "        cv_scores['accuracies'].append(accuracy_score(y_val_fold, y_pred))\n",
    "        cv_scores['precisions'].append(precision_score(y_val_fold, y_pred, average='macro'))\n",
    "        cv_scores['recalls'].append(recall_score(y_val_fold, y_pred, average='macro'))\n",
    "        cv_scores['f1_scores'].append(f1_score(y_val_fold, y_pred, average='macro'))\n",
    "    \n",
    "    # Train final model on full training data\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate_downstream_task(clf, test_features, test_labels)\n",
    "    \n",
    "    return clf, cv_scores, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1f504e9-893b-4ebf-8bad-9dbc5b6e0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Plot Results\n",
    "def plot_results(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b4c487-e7cb-4094-ac13-31dfd37d99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pretext_pipeline(\n",
    "        data_dir, x_augmented, y_augmented, \n",
    "        input_shape=(128, 128, 1), num_classes=4, architecture_name='cnn', fine_tune=True,\n",
    "        epochs=10, validation_split=0.25\n",
    "    ):\n",
    "    print(f'>>> STARTED PRETEXT TASK\\n> folder: {data_dir} | {architecture_name}')\n",
    "\n",
    "    # if load_model(architecture_name, data_dir) is not None:\n",
    "    #     return\n",
    "    \n",
    "    # Build and Train Pretext Task Model\n",
    "    pretext_model = build_custom_cnn_model(\n",
    "        input_shape=input_shape,\n",
    "        num_classes=num_classes,\n",
    "        architecture_name=architecture_name,\n",
    "        fine_tune=fine_tune\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "    \n",
    "    # Use validation split from training data\n",
    "    history = pretext_model.fit(\n",
    "        x_augmented, y_augmented,\n",
    "        epochs=epochs,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[early_stopping, lr_scheduler]\n",
    "    )\n",
    "    \n",
    "    # Plot Results\n",
    "    # plot_results(history)\n",
    "    \n",
    "    # Save the trained model\n",
    "    save_model(pretext_model, architecture_name, data_dir)\n",
    "\n",
    "    print(f'>>> FINISHED PRETEXT TASK\\n> folder: {data_dir} | {architecture_name}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ab2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_downstream_pipeline(data_dir, x_train, y_train, x_test, y_test, architecture_name='cnn', downstream_classifier='random_forest', layer_index=-2):\n",
    "    print(f'>>> STARTED DOWNSTREAM TASK\\n> folder: {data_dir}\\n> {architecture_name} | {downstream_classifier}')\n",
    "    \n",
    "    # Load the saved pretext model\n",
    "    pretext_model = load_model(architecture_name, data_dir)\n",
    "    \n",
    "    # Extract Features for both training and test sets\n",
    "    train_features = extract_features(pretext_model, x_train, layer_index=layer_index)\n",
    "    test_features = extract_features(pretext_model, x_test, layer_index=layer_index)\n",
    "    \n",
    "    # Train and evaluate the Downstream Task\n",
    "    clf, cv_scores, test_metrics = train_downstream_task(\n",
    "        train_features, y_train,\n",
    "        test_features, y_test,\n",
    "        classifier=downstream_classifier\n",
    "    )\n",
    "    \n",
    "    print(f'>>> FINISHED DOWNSTREAM TASK\\n> folder: {data_dir}\\n> {architecture_name} | {downstream_classifier}\\n')\n",
    "    return clf, cv_scores, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97712e16-b763-4753-924d-af474b7efd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(data_dirs, architecture_names, classifiers, pretext_trained=False):\n",
    "    results_tracker = ResultsTracker.ResultsTracker() \n",
    "\n",
    "    for data_dir in data_dirs:\n",
    "        # Load data with train/test split | Augmenet the data\n",
    "        x_train, y_train, x_test, y_test = load_and_split_data(data_dir)\n",
    "        x_augmented, y_augmented = preprocess_data(x_train)\n",
    "\n",
    "        # Run all the pretext task\n",
    "        for architecture_name in architecture_names:\n",
    "            run_pretext_pipeline(\n",
    "                data_dir, x_augmented, y_augmented, \n",
    "                input_shape=(128, 128, 1), num_classes=4, architecture_name=architecture_name, fine_tune=True,\n",
    "                epochs=10, validation_split=0.25\n",
    "            )\n",
    "            \n",
    "        # Run (for all the pretext models) all the downstream tasks\n",
    "        for architecture_name in architecture_names:\n",
    "            for classifier in classifiers:\n",
    "                clf, cv_scores, test_metrics = run_downstream_pipeline(\n",
    "                                                data_dir, x_train, y_train, x_test, y_test, \n",
    "                                                architecture_name, classifier, -2\n",
    "                                            )\n",
    "                \n",
    "                # Track results\n",
    "                results_tracker.add_result(\n",
    "                    data_dir=data_dir,\n",
    "                    architecture=architecture_name,\n",
    "                    classifier=classifier,\n",
    "                    cv_metrics=cv_scores,\n",
    "                    test_metrics=test_metrics\n",
    "                )\n",
    "\n",
    "                # results_tracker.display_results()\n",
    "    \n",
    "    # Display and save results\n",
    "    results_tracker.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dcfb5f2-112b-4b14-9b06-9e5b774d09d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Distribution:\n",
      "  Class      Total      Train       Test   \n",
      "----------------------------------------\n",
      "    0         174        139         35    \n",
      "    1         107         85         22    \n",
      "    2          92         73         19    \n",
      "    3         129        103         26    \n",
      "    4         128        102         26    \n",
      "    5         129        103         26    \n",
      "    6         128        102         26    \n",
      "    7         176        140         36    \n",
      "    8         108         86         22    \n",
      "    9         174        139         35    \n",
      "\n",
      "Summary of Loaded Data:\n",
      "[DATAINFO] Total images: 1345\n",
      "[DATAINFO] Training set: 1072 images (80%)\n",
      "[DATAINFO] Test set: 273 images (20%)\n",
      "[DATAINFO] Image shape: (128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 14:26:35.470441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-10-28 14:26:35.470534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-Q7I3MQ5): /proc/driver/nvidia/version does not exist\n",
      "2024-10-28 14:26:35.471322: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 4288 augmented images generated each of shape (128, 128, 1) with 4288 labels\n",
      ">>> STARTED PRETEXT TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth | cnn\n",
      "> pretext task training model: input_shape (128, 128, 1), num_classes 4, architecture_name cnn\n",
      "Model: \"model\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                                         Output Shape                                    Param #           \n",
      "========================================================================================================================\n",
      " input_1 (InputLayer)                                 [(None, 128, 128, 1)]                           0                 \n",
      "                                                                                                                        \n",
      " conv2d (Conv2D)                                      (None, 128, 128, 32)                            320               \n",
      "                                                                                                                        \n",
      " batch_normalization (BatchNormalization)             (None, 128, 128, 32)                            128               \n",
      "                                                                                                                        \n",
      " max_pooling2d (MaxPooling2D)                         (None, 64, 64, 32)                              0                 \n",
      "                                                                                                                        \n",
      " conv2d_1 (Conv2D)                                    (None, 64, 64, 64)                              18496             \n",
      "                                                                                                                        \n",
      " batch_normalization_1 (BatchNormalization)           (None, 64, 64, 64)                              256               \n",
      "                                                                                                                        \n",
      " max_pooling2d_1 (MaxPooling2D)                       (None, 32, 32, 64)                              0                 \n",
      "                                                                                                                        \n",
      " conv2d_2 (Conv2D)                                    (None, 32, 32, 128)                             73856             \n",
      "                                                                                                                        \n",
      " batch_normalization_2 (BatchNormalization)           (None, 32, 32, 128)                             512               \n",
      "                                                                                                                        \n",
      " max_pooling2d_2 (MaxPooling2D)                       (None, 16, 16, 128)                             0                 \n",
      "                                                                                                                        \n",
      " conv2d_3 (Conv2D)                                    (None, 16, 16, 256)                             295168            \n",
      "                                                                                                                        \n",
      " batch_normalization_3 (BatchNormalization)           (None, 16, 16, 256)                             1024              \n",
      "                                                                                                                        \n",
      " global_average_pooling2d (GlobalAveragePooling2D)    (None, 256)                                     0                 \n",
      "                                                                                                                        \n",
      " dense (Dense)                                        (None, 512)                                     131584            \n",
      "                                                                                                                        \n",
      " dropout (Dropout)                                    (None, 512)                                     0                 \n",
      "                                                                                                                        \n",
      " dense_1 (Dense)                                      (None, 4)                                       2052              \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 523,396\n",
      "Trainable params: 522,436\n",
      "Non-trainable params: 960\n",
      "________________________________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "101/101 [==============================] - 38s 350ms/step - loss: 0.6713 - accuracy: 0.8635 - val_loss: 2.6074 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 33s 322ms/step - loss: 0.2436 - accuracy: 0.9978 - val_loss: 3.3717 - val_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 33s 331ms/step - loss: 0.1798 - accuracy: 0.9978 - val_loss: 2.8885 - val_accuracy: 0.2640 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 33s 332ms/step - loss: 0.1327 - accuracy: 0.9988 - val_loss: 5.1567 - val_accuracy: 0.2500 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Model successfully saved as exp-02/pretext_models/pretext_model_qpm_synth_cnn.h5\n",
      ">>> FINISHED PRETEXT TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth | cnn\n",
      "\n",
      ">>> STARTED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | random_forest\n",
      "Model successfully loaded from exp-02/pretext_models/pretext_model_qpm_synth_cnn.h5\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "34/34 [==============================] - 3s 90ms/step\n",
      "> extracted features of shape (1072, 512)\n",
      "9/9 [==============================] - 1s 99ms/step\n",
      "> extracted features of shape (273, 512)\n",
      "> performing downstream task with random_forest\n",
      ">>> FINISHED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | random_forest\n",
      "\n",
      "\n",
      "=== Results: Dataset: <qpm_synth> | Pretext Model: <cnn> ===\n",
      "+---------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| Classifier    |   Test_Accuracy |   Test_Precision |   Test_Recall |   Test_F1 | CV_Accuracy   | CV_Precision   | CV_Recall   | CV_F1    |\n",
      "+===============+=================+==================+===============+===========+===============+================+=============+==========+\n",
      "| random_forest |          58.600 |           56.800 |        57.400 |    56.700 | 61.01.8      | 61.61.9       | 61.02.5    | 60.32.4 |\n",
      "+---------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "+---------------+-----------------------------------+\n",
      "| Classifier    | Test_Confusion_Matrix             |\n",
      "+===============+===================================+\n",
      "| random_forest | [[23  3  2  1  1  0  0  2  2  1]  |\n",
      "|               |  [ 6  8  4  0  3  0  0  0  0  1]  |\n",
      "|               |  [ 0  3 13  0  0  0  0  0  1  2]  |\n",
      "|               |  [ 2  0  0 19  2  0  1  2  0  0]  |\n",
      "|               |  [ 3  2  0  2  4  0  0  2  4  9]  |\n",
      "|               |  [ 0  0  0  2  0 19  3  2  0  0]  |\n",
      "|               |  [ 0  0  0  0  0  3 21  1  1  0]  |\n",
      "|               |  [ 1  0  0  5  1  0  1 23  1  4]  |\n",
      "|               |  [ 3  1  0  1  3  0  1  1  7  5]  |\n",
      "|               |  [ 1  1  3  1  2  0  1  0  3 23]] |\n",
      "+---------------+-----------------------------------+\n",
      ">>> STARTED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | svm\n",
      "Model successfully loaded from exp-02/pretext_models/pretext_model_qpm_synth_cnn.h5\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "34/34 [==============================] - 3s 90ms/step\n",
      "> extracted features of shape (1072, 512)\n",
      "9/9 [==============================] - 1s 98ms/step\n",
      "> extracted features of shape (273, 512)\n",
      "> performing downstream task with svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> FINISHED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | svm\n",
      "\n",
      "\n",
      "=== Results: Dataset: <qpm_synth> | Pretext Model: <cnn> ===\n",
      "+---------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| Classifier    |   Test_Accuracy |   Test_Precision |   Test_Recall |   Test_F1 | CV_Accuracy   | CV_Precision   | CV_Recall   | CV_F1    |\n",
      "+===============+=================+==================+===============+===========+===============+================+=============+==========+\n",
      "| random_forest |          58.600 |           56.800 |        57.400 |    56.700 | 61.01.8      | 61.61.9       | 61.02.5    | 60.32.4 |\n",
      "+---------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| svm           |          21.200 |           16.100 |        16.600 |     9.500 | 17.90.6      | 3.80.4        | 13.80.5    | 5.80.3  |\n",
      "+---------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "+---------------+-----------------------------------+\n",
      "| Classifier    | Test_Confusion_Matrix             |\n",
      "+===============+===================================+\n",
      "| random_forest | [[23  3  2  1  1  0  0  2  2  1]  |\n",
      "|               |  [ 6  8  4  0  3  0  0  0  0  1]  |\n",
      "|               |  [ 0  3 13  0  0  0  0  0  1  2]  |\n",
      "|               |  [ 2  0  0 19  2  0  1  2  0  0]  |\n",
      "|               |  [ 3  2  0  2  4  0  0  2  4  9]  |\n",
      "|               |  [ 0  0  0  2  0 19  3  2  0  0]  |\n",
      "|               |  [ 0  0  0  0  0  3 21  1  1  0]  |\n",
      "|               |  [ 1  0  0  5  1  0  1 23  1  4]  |\n",
      "|               |  [ 3  1  0  1  3  0  1  1  7  5]  |\n",
      "|               |  [ 1  1  3  1  2  0  1  0  3 23]] |\n",
      "+---------------+-----------------------------------+\n",
      "| svm           | [[18  0  0  0  0  0  0  8  0  9]  |\n",
      "|               |  [13  0  0  0  0  0  0  6  0  3]  |\n",
      "|               |  [18  0  1  0  0  0  0  0  0  0]  |\n",
      "|               |  [ 4  0  0  0  0  0  0 19  0  3]  |\n",
      "|               |  [10  0  0  0  0  0  0  8  0  8]  |\n",
      "|               |  [ 0  0  0  0  0  0  0 26  0  0]  |\n",
      "|               |  [ 2  0  0  0  0  0  0 24  0  0]  |\n",
      "|               |  [ 2  0  0  0  0  0  0 31  0  3]  |\n",
      "|               |  [13  0  0  0  0  0  0  2  0  7]  |\n",
      "|               |  [14  0  0  0  0  0  0 13  0  8]] |\n",
      "+---------------+-----------------------------------+\n",
      ">>> STARTED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | gradient_boosting\n",
      "Model successfully loaded from exp-02/pretext_models/pretext_model_qpm_synth_cnn.h5\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "34/34 [==============================] - 3s 90ms/step\n",
      "> extracted features of shape (1072, 512)\n",
      "9/9 [==============================] - 1s 94ms/step\n",
      "> extracted features of shape (273, 512)\n",
      "> performing downstream task with gradient_boosting\n",
      ">>> FINISHED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | gradient_boosting\n",
      "\n",
      "\n",
      "=== Results: Dataset: <qpm_synth> | Pretext Model: <cnn> ===\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| Classifier        |   Test_Accuracy |   Test_Precision |   Test_Recall |   Test_F1 | CV_Accuracy   | CV_Precision   | CV_Recall   | CV_F1    |\n",
      "+===================+=================+==================+===============+===========+===============+================+=============+==========+\n",
      "| random_forest     |          58.600 |           56.800 |        57.400 |    56.700 | 61.01.8      | 61.61.9       | 61.02.5    | 60.32.4 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| svm               |          21.200 |           16.100 |        16.600 |     9.500 | 17.90.6      | 3.80.4        | 13.80.5    | 5.80.3  |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| gradient_boosting |          66.300 |           66.200 |        65.200 |    65.200 | 66.42.7      | 67.33.1       | 65.73.2    | 65.73.4 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "+-------------------+-----------------------------------+\n",
      "| Classifier        | Test_Confusion_Matrix             |\n",
      "+===================+===================================+\n",
      "| random_forest     | [[23  3  2  1  1  0  0  2  2  1]  |\n",
      "|                   |  [ 6  8  4  0  3  0  0  0  0  1]  |\n",
      "|                   |  [ 0  3 13  0  0  0  0  0  1  2]  |\n",
      "|                   |  [ 2  0  0 19  2  0  1  2  0  0]  |\n",
      "|                   |  [ 3  2  0  2  4  0  0  2  4  9]  |\n",
      "|                   |  [ 0  0  0  2  0 19  3  2  0  0]  |\n",
      "|                   |  [ 0  0  0  0  0  3 21  1  1  0]  |\n",
      "|                   |  [ 1  0  0  5  1  0  1 23  1  4]  |\n",
      "|                   |  [ 3  1  0  1  3  0  1  1  7  5]  |\n",
      "|                   |  [ 1  1  3  1  2  0  1  0  3 23]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| svm               | [[18  0  0  0  0  0  0  8  0  9]  |\n",
      "|                   |  [13  0  0  0  0  0  0  6  0  3]  |\n",
      "|                   |  [18  0  1  0  0  0  0  0  0  0]  |\n",
      "|                   |  [ 4  0  0  0  0  0  0 19  0  3]  |\n",
      "|                   |  [10  0  0  0  0  0  0  8  0  8]  |\n",
      "|                   |  [ 0  0  0  0  0  0  0 26  0  0]  |\n",
      "|                   |  [ 2  0  0  0  0  0  0 24  0  0]  |\n",
      "|                   |  [ 2  0  0  0  0  0  0 31  0  3]  |\n",
      "|                   |  [13  0  0  0  0  0  0  2  0  7]  |\n",
      "|                   |  [14  0  0  0  0  0  0 13  0  8]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| gradient_boosting | [[23  2  2  1  2  0  0  0  2  3]  |\n",
      "|                   |  [ 4 11  2  1  1  0  0  0  0  3]  |\n",
      "|                   |  [ 0  3 15  0  0  0  0  0  0  1]  |\n",
      "|                   |  [ 2  0  0 18  1  0  1  4  0  0]  |\n",
      "|                   |  [ 4  0  0  0  6  0  0  3  4  9]  |\n",
      "|                   |  [ 1  0  0  0  0 19  2  2  2  0]  |\n",
      "|                   |  [ 0  0  0  0  0  4 19  2  1  0]  |\n",
      "|                   |  [ 0  0  0  1  0  0  0 35  0  0]  |\n",
      "|                   |  [ 1  0  0  0  5  0  0  1 13  2]  |\n",
      "|                   |  [ 3  1  3  1  4  0  0  0  1 22]] |\n",
      "+-------------------+-----------------------------------+\n",
      ">>> STARTED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | xgboost\n",
      "Model successfully loaded from exp-02/pretext_models/pretext_model_qpm_synth_cnn.h5\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "34/34 [==============================] - 4s 97ms/step\n",
      "> extracted features of shape (1072, 512)\n",
      "9/9 [==============================] - 1s 100ms/step\n",
      "> extracted features of shape (273, 512)\n",
      "> performing downstream task with xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:43:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:45:56] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:47:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:49:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:51:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:54:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> FINISHED DOWNSTREAM TASK\n",
      "> folder: /mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/synth\n",
      "> cnn | xgboost\n",
      "\n",
      "\n",
      "=== Results: Dataset: <qpm_synth> | Pretext Model: <cnn> ===\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| Classifier        |   Test_Accuracy |   Test_Precision |   Test_Recall |   Test_F1 | CV_Accuracy   | CV_Precision   | CV_Recall   | CV_F1    |\n",
      "+===================+=================+==================+===============+===========+===============+================+=============+==========+\n",
      "| random_forest     |          58.600 |           56.800 |        57.400 |    56.700 | 61.01.8      | 61.61.9       | 61.02.5    | 60.32.4 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| svm               |          21.200 |           16.100 |        16.600 |     9.500 | 17.90.6      | 3.80.4        | 13.80.5    | 5.80.3  |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| gradient_boosting |          66.300 |           66.200 |        65.200 |    65.200 | 66.42.7      | 67.33.1       | 65.73.2    | 65.73.4 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| xgboost           |          69.600 |           70.000 |        69.000 |    69.100 | 67.72.1      | 68.93.1       | 67.72.6    | 67.42.6 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "+-------------------+-----------------------------------+\n",
      "| Classifier        | Test_Confusion_Matrix             |\n",
      "+===================+===================================+\n",
      "| random_forest     | [[23  3  2  1  1  0  0  2  2  1]  |\n",
      "|                   |  [ 6  8  4  0  3  0  0  0  0  1]  |\n",
      "|                   |  [ 0  3 13  0  0  0  0  0  1  2]  |\n",
      "|                   |  [ 2  0  0 19  2  0  1  2  0  0]  |\n",
      "|                   |  [ 3  2  0  2  4  0  0  2  4  9]  |\n",
      "|                   |  [ 0  0  0  2  0 19  3  2  0  0]  |\n",
      "|                   |  [ 0  0  0  0  0  3 21  1  1  0]  |\n",
      "|                   |  [ 1  0  0  5  1  0  1 23  1  4]  |\n",
      "|                   |  [ 3  1  0  1  3  0  1  1  7  5]  |\n",
      "|                   |  [ 1  1  3  1  2  0  1  0  3 23]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| svm               | [[18  0  0  0  0  0  0  8  0  9]  |\n",
      "|                   |  [13  0  0  0  0  0  0  6  0  3]  |\n",
      "|                   |  [18  0  1  0  0  0  0  0  0  0]  |\n",
      "|                   |  [ 4  0  0  0  0  0  0 19  0  3]  |\n",
      "|                   |  [10  0  0  0  0  0  0  8  0  8]  |\n",
      "|                   |  [ 0  0  0  0  0  0  0 26  0  0]  |\n",
      "|                   |  [ 2  0  0  0  0  0  0 24  0  0]  |\n",
      "|                   |  [ 2  0  0  0  0  0  0 31  0  3]  |\n",
      "|                   |  [13  0  0  0  0  0  0  2  0  7]  |\n",
      "|                   |  [14  0  0  0  0  0  0 13  0  8]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| gradient_boosting | [[23  2  2  1  2  0  0  0  2  3]  |\n",
      "|                   |  [ 4 11  2  1  1  0  0  0  0  3]  |\n",
      "|                   |  [ 0  3 15  0  0  0  0  0  0  1]  |\n",
      "|                   |  [ 2  0  0 18  1  0  1  4  0  0]  |\n",
      "|                   |  [ 4  0  0  0  6  0  0  3  4  9]  |\n",
      "|                   |  [ 1  0  0  0  0 19  2  2  2  0]  |\n",
      "|                   |  [ 0  0  0  0  0  4 19  2  1  0]  |\n",
      "|                   |  [ 0  0  0  1  0  0  0 35  0  0]  |\n",
      "|                   |  [ 1  0  0  0  5  0  0  1 13  2]  |\n",
      "|                   |  [ 3  1  3  1  4  0  0  0  1 22]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| xgboost           | [[25  3  2  0  0  0  0  1  2  2]  |\n",
      "|                   |  [ 5 14  2  1  0  0  0  0  0  0]  |\n",
      "|                   |  [ 0  2 15  0  0  0  0  0  1  1]  |\n",
      "|                   |  [ 1  0  0 19  2  0  1  3  0  0]  |\n",
      "|                   |  [ 2  0  0  0 10  0  0  2  4  8]  |\n",
      "|                   |  [ 1  0  0  0  0 21  0  2  2  0]  |\n",
      "|                   |  [ 0  0  0  0  0  4 20  1  1  0]  |\n",
      "|                   |  [ 1  0  0  1  0  1  0 32  0  1]  |\n",
      "|                   |  [ 2  0  0  0  5  0  0  3 12  0]  |\n",
      "|                   |  [ 3  1  3  1  4  0  0  0  1 22]] |\n",
      "+-------------------+-----------------------------------+\n",
      "\n",
      "=== Results: Dataset: <qpm_synth> | Pretext Model: <cnn> ===\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| Classifier        |   Test_Accuracy |   Test_Precision |   Test_Recall |   Test_F1 | CV_Accuracy   | CV_Precision   | CV_Recall   | CV_F1    |\n",
      "+===================+=================+==================+===============+===========+===============+================+=============+==========+\n",
      "| random_forest     |          58.600 |           56.800 |        57.400 |    56.700 | 61.01.8      | 61.61.9       | 61.02.5    | 60.32.4 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| svm               |          21.200 |           16.100 |        16.600 |     9.500 | 17.90.6      | 3.80.4        | 13.80.5    | 5.80.3  |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| gradient_boosting |          66.300 |           66.200 |        65.200 |    65.200 | 66.42.7      | 67.33.1       | 65.73.2    | 65.73.4 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "| xgboost           |          69.600 |           70.000 |        69.000 |    69.100 | 67.72.1      | 68.93.1       | 67.72.6    | 67.42.6 |\n",
      "+-------------------+-----------------+------------------+---------------+-----------+---------------+----------------+-------------+----------+\n",
      "+-------------------+-----------------------------------+\n",
      "| Classifier        | Test_Confusion_Matrix             |\n",
      "+===================+===================================+\n",
      "| random_forest     | [[23  3  2  1  1  0  0  2  2  1]  |\n",
      "|                   |  [ 6  8  4  0  3  0  0  0  0  1]  |\n",
      "|                   |  [ 0  3 13  0  0  0  0  0  1  2]  |\n",
      "|                   |  [ 2  0  0 19  2  0  1  2  0  0]  |\n",
      "|                   |  [ 3  2  0  2  4  0  0  2  4  9]  |\n",
      "|                   |  [ 0  0  0  2  0 19  3  2  0  0]  |\n",
      "|                   |  [ 0  0  0  0  0  3 21  1  1  0]  |\n",
      "|                   |  [ 1  0  0  5  1  0  1 23  1  4]  |\n",
      "|                   |  [ 3  1  0  1  3  0  1  1  7  5]  |\n",
      "|                   |  [ 1  1  3  1  2  0  1  0  3 23]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| svm               | [[18  0  0  0  0  0  0  8  0  9]  |\n",
      "|                   |  [13  0  0  0  0  0  0  6  0  3]  |\n",
      "|                   |  [18  0  1  0  0  0  0  0  0  0]  |\n",
      "|                   |  [ 4  0  0  0  0  0  0 19  0  3]  |\n",
      "|                   |  [10  0  0  0  0  0  0  8  0  8]  |\n",
      "|                   |  [ 0  0  0  0  0  0  0 26  0  0]  |\n",
      "|                   |  [ 2  0  0  0  0  0  0 24  0  0]  |\n",
      "|                   |  [ 2  0  0  0  0  0  0 31  0  3]  |\n",
      "|                   |  [13  0  0  0  0  0  0  2  0  7]  |\n",
      "|                   |  [14  0  0  0  0  0  0 13  0  8]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| gradient_boosting | [[23  2  2  1  2  0  0  0  2  3]  |\n",
      "|                   |  [ 4 11  2  1  1  0  0  0  0  3]  |\n",
      "|                   |  [ 0  3 15  0  0  0  0  0  0  1]  |\n",
      "|                   |  [ 2  0  0 18  1  0  1  4  0  0]  |\n",
      "|                   |  [ 4  0  0  0  6  0  0  3  4  9]  |\n",
      "|                   |  [ 1  0  0  0  0 19  2  2  2  0]  |\n",
      "|                   |  [ 0  0  0  0  0  4 19  2  1  0]  |\n",
      "|                   |  [ 0  0  0  1  0  0  0 35  0  0]  |\n",
      "|                   |  [ 1  0  0  0  5  0  0  1 13  2]  |\n",
      "|                   |  [ 3  1  3  1  4  0  0  0  1 22]] |\n",
      "+-------------------+-----------------------------------+\n",
      "| xgboost           | [[25  3  2  0  0  0  0  1  2  2]  |\n",
      "|                   |  [ 5 14  2  1  0  0  0  0  0  0]  |\n",
      "|                   |  [ 0  2 15  0  0  0  0  0  1  1]  |\n",
      "|                   |  [ 1  0  0 19  2  0  1  3  0  0]  |\n",
      "|                   |  [ 2  0  0  0 10  0  0  2  4  8]  |\n",
      "|                   |  [ 1  0  0  0  0 21  0  2  2  0]  |\n",
      "|                   |  [ 0  0  0  0  0  4 20  1  1  0]  |\n",
      "|                   |  [ 1  0  0  1  0  1  0 32  0  1]  |\n",
      "|                   |  [ 2  0  0  0  5  0  0  3 12  0]  |\n",
      "|                   |  [ 3  1  3  1  4  0  0  0  1 22]] |\n",
      "+-------------------+-----------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set_random_seeds()\n",
    "\n",
    "run_experiments(\n",
    "    data_dirs=data_dirs[:1],\n",
    "    architecture_names=architecture_names[:1],\n",
    "    classifiers=classifiers\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
