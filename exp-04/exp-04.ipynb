{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 1] - Import statements\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from tabulate import tabulate\n",
    "from typing import Dict, List, Any\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 2] - Set global constants and configurations [config.py]\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "EXPERIMENT_BASE_DIR = 'exp-04'\n",
    "MODEL_DIR = os.path.join(EXPERIMENT_BASE_DIR, \"pretext_models\")\n",
    "DATA_DIR = os.path.join(EXPERIMENT_BASE_DIR, \"processed_data\")\n",
    "RESULTS_DIR = os.path.join(EXPERIMENT_BASE_DIR, \"results\")\n",
    "\n",
    "# Create required directories\n",
    "for dir_path in [MODEL_DIR, DATA_DIR, RESULTS_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "experiment_parameters = {\n",
    "    # Parameters\n",
    "    'mode': 'all',  # choices: 'process', 'pretext', 'downstream', 'all'\n",
    "    'split_index': 0,\n",
    "    'architecture': 'cnn',  # options: specific architecture like 'cnn' or 'all'\n",
    "    'classifier': 'all',  # or specific: 'random_forest', 'svm', 'gradient_boosting', 'xgboost'\n",
    "    # Data directory\n",
    "    'data_dir': '/mnt/c/Users/Siam/OneDrive - Tuskegee University/ai-arni-nsf/SAMPLE_dataset_public/png_images/qpm/real'\n",
    "}\n",
    "\n",
    "# Configuration dictionary\n",
    "hyperparameters = {\n",
    "    # Data loading and splitting\n",
    "    'img_size': (128, 128),\n",
    "    'color_mode': 'grayscale',\n",
    "    'test_split_size': 0.2,\n",
    "    'test_split_index': 0,\n",
    "\n",
    "    # Model architecture\n",
    "    'input_shape': (128, 128, 1),\n",
    "    'num_classes': 4,\n",
    "    'fine_tune': True,\n",
    "\n",
    "    # CNN architecture\n",
    "    'cnn_filters': [32, 64, 128, 256],\n",
    "    'cnn_kernel_size': (3, 3),\n",
    "    'cnn_pool_size': (2, 2),\n",
    "    'cnn_dense_units': 512,\n",
    "    'cnn_dropout_rate': 0.5,\n",
    "    'cnn_loss_function': 'sparse_categorical_crossentropy',\n",
    "    'cnn_activation_function': 'relu',\n",
    "    'cnn_padding': 'same',\n",
    "\n",
    "    # Other Pretext Architectures\n",
    "    'pretained_model_weights': 'imagenet',\n",
    "\n",
    "    # Training configuration\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'validation_split': 0.25,\n",
    "    'learning_rate': 0.001,\n",
    "    'early_stopping_patience': 3,\n",
    "    'lr_reduction_patience': 3,\n",
    "    'lr_reduction_factor': 0.5,\n",
    "\n",
    "    # Downstream task\n",
    "    'feature_extraction_layer': -2,\n",
    "    'rf_n_estimators': 100,\n",
    "    'svm_kernel': 'linear',\n",
    "    'gb_n_estimators': 100,\n",
    "    'xgb_n_estimators': 100,\n",
    "    'cv_splits': 5,\n",
    "}\n",
    "\n",
    "architecture_list = [\n",
    "    'cnn',\n",
    "    'resnet50',\n",
    "    'resnet101',\n",
    "    'resnet152',\n",
    "    'efficientnetb0',\n",
    "    'vgg16',\n",
    "    'vgg19',\n",
    "    'inceptionv3',\n",
    "    'unet'\n",
    "]\n",
    "\n",
    "classifier_list = [\n",
    "    'random_forest', \n",
    "    'svm', \n",
    "    'gradient_boosting', \n",
    "    'xgboost'\n",
    "]\n",
    "\n",
    "def display_configurations():\n",
    "    print(\"\\n===== Experiment Configurations =====\\n\")\n",
    "    \n",
    "    print(\">>> Data Loading and Splitting <<<\")\n",
    "    for key in ['img_size', 'color_mode', 'test_split_size', 'test_split_index']:\n",
    "        print(f\"{key}: {hyperparameters[key]}\")\n",
    "    \n",
    "    print(\"\\n>>> Model Architecture <<<\")\n",
    "    for key in ['input_shape', 'num_classes', 'fine_tune']:\n",
    "        print(f\"{key}: {hyperparameters[key]}\")\n",
    "    \n",
    "    print(\"\\n>>> CNN Architecture <<<\")\n",
    "    for key in ['cnn_filters', 'cnn_kernel_size', 'cnn_pool_size', 'cnn_dense_units', 'cnn_dropout_rate', 'cnn_loss_function', 'cnn_activation_function', 'cnn_padding']:\n",
    "        print(f\"{key}: {hyperparameters[key]}\")\n",
    "\n",
    "    print(\"\\n>>> Other Pretext Architectures <<<\")\n",
    "    for key in ['pretained_model_weights']:\n",
    "        print(f\"{key}: {hyperparameters[key]}\")\n",
    "    \n",
    "    print(\"\\n>>> Training Configuration <<<\")\n",
    "    for key in ['batch_size', 'epochs', 'validation_split', 'learning_rate', 'early_stopping_patience', 'lr_reduction_patience', 'lr_reduction_factor']:\n",
    "        print(f\"{key}: {hyperparameters[key]}\")\n",
    "    \n",
    "    print(\"\\n>>> Downstream Task Configuration <<<\")\n",
    "    for key in ['feature_extraction_layer', 'rf_n_estimators', 'svm_kernel', 'gb_n_estimators', 'xgb_n_estimators', 'cv_splits']:\n",
    "        print(f\"{key}: {hyperparameters[key]}\")\n",
    "    \n",
    "    print(\"\\n>>> Architectures <<<\")\n",
    "    print(\", \".join(architecture_list))\n",
    "    \n",
    "    print(\"\\n>>> Classifiers <<<\")\n",
    "    print(\", \".join(classifier_list))\n",
    "    \n",
    "    print(\"\\n>>> Experiment Parameters <<<\")\n",
    "    for key, value in experiment_parameters.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(\"\\n=====================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 3] - Utility functions [seeds.py/ResultsTracker.py]\n",
    "def set_all_seeds(seed=42):\n",
    "    \"\"\"Set all seeds to make results reproducible\"\"\"\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # Force TensorFlow to use single thread\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "class ResultsTracker:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "\n",
    "    def add_result(self, data_dir: str, architecture: str, classifier: str, \n",
    "                   cv_metrics: Dict[str, List[float]], test_metrics: Dict[str, Any]):\n",
    "        result = {\n",
    "            'Dataset': f\"{data_dir.split('/')[-2]}_{data_dir.split('/')[-1]}\",\n",
    "            'Architecture': architecture,\n",
    "            'Classifier': classifier,\n",
    "            'CV_Accuracy': f\"{np.mean(cv_metrics['accuracies'])*100:.1f}±{np.std(cv_metrics['accuracies'])*100:.1f}\",\n",
    "            'CV_Precision': f\"{np.mean(cv_metrics['precisions'])*100:.1f}±{np.std(cv_metrics['precisions'])*100:.1f}\",\n",
    "            'CV_Recall': f\"{np.mean(cv_metrics['recalls'])*100:.1f}±{np.std(cv_metrics['recalls'])*100:.1f}\",\n",
    "            'CV_F1': f\"{np.mean(cv_metrics['f1_scores'])*100:.1f}±{np.std(cv_metrics['f1_scores'])*100:.1f}\",\n",
    "            'Test_Accuracy': f\"{test_metrics['accuracy']*100:.1f}\",\n",
    "            'Test_Precision': f\"{test_metrics['precision']*100:.1f}\",\n",
    "            'Test_Recall': f\"{test_metrics['recall']*100:.1f}\",\n",
    "            'Test_F1': f\"{test_metrics['f1']*100:.1f}\",\n",
    "            'Test_Confusion_Matrix': f\"{test_metrics['confusion_matrix']}\"\n",
    "        }\n",
    "        self.results.append(result)\n",
    "\n",
    "    # def display_results(self):\n",
    "    #     if not self.results:\n",
    "    #         print(\"> No results to display\")\n",
    "    #         return\n",
    "\n",
    "    #     df = pd.DataFrame(self.results)\n",
    "    #     grouped = df.groupby(['Dataset', 'Architecture'])\n",
    "\n",
    "    #     for (dataset, arch), group in grouped:\n",
    "    #         print(f\"\\n=== Results: Dataset: <{dataset}> | Pretext Model: <{arch}> ===\")\n",
    "            \n",
    "    #         display_cols = [\n",
    "    #             'Classifier',\n",
    "    #             'Test_Accuracy', 'Test_Precision', 'Test_Recall', 'Test_F1',\n",
    "    #             'CV_Accuracy', 'CV_Precision', 'CV_Recall', 'CV_F1'\n",
    "    #         ]\n",
    "            \n",
    "    #         display_df = group[display_cols].copy()\n",
    "    #         print(tabulate(display_df, headers='keys', tablefmt='grid', showindex=False))\n",
    "            \n",
    "    #         display_cols = ['Classifier', 'Test_Confusion_Matrix']\n",
    "    #         display_df = group[display_cols].copy()\n",
    "    #         print(tabulate(display_df, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "    def display_results(self):\n",
    "        if not self.results:\n",
    "            print(\"> No results to display\")\n",
    "            return\n",
    "\n",
    "        df = pd.DataFrame(self.results)\n",
    "        grouped = df.groupby(['Dataset', 'Architecture'])\n",
    "\n",
    "        for (dataset, arch), group in grouped:\n",
    "            print(f\"\\n=== Results: Dataset: <{dataset}> | Pretext Model: <{arch}> ===\")\n",
    "\n",
    "            # Display test and cross-validation metrics\n",
    "            display_cols = [\n",
    "                'Classifier',\n",
    "                'Test_Accuracy', 'Test_Precision', 'Test_Recall', 'Test_F1',\n",
    "                'CV_Accuracy', 'CV_Precision', 'CV_Recall', 'CV_F1'\n",
    "            ]\n",
    "            \n",
    "            display_df = group[display_cols].copy()\n",
    "            print(\"\\nMetrics Summary:\")\n",
    "            print(tabulate(display_df, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "            # Separate classifiers and confusion matrices\n",
    "            classifier_names = group['Classifier'].tolist()\n",
    "            confusion_matrices = group['Test_Confusion_Matrix'].tolist()\n",
    "\n",
    "            # Build display format for classifiers and confusion matrices\n",
    "            display_confusion_matrix = pd.DataFrame([confusion_matrices], columns=classifier_names, index=[\"Confusion Matrix\"])\n",
    "            display_classifiers = pd.DataFrame([classifier_names], columns=classifier_names, index=[\"Classifier\"])\n",
    "            combined_df = pd.concat([display_classifiers, display_confusion_matrix])\n",
    "            print(tabulate(combined_df, headers='keys', tablefmt='grid', showindex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 4] - Data Processing Functions [data_processor.py]\n",
    "def load_and_split_data(data_dir, split_index=0):\n",
    "    images_by_class = {}\n",
    "    labels_by_class = {}\n",
    "\n",
    "    class_folders = sorted(os.listdir(data_dir))\n",
    "    for class_index, class_folder in enumerate(class_folders):\n",
    "        class_path = os.path.join(data_dir, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            img_files = sorted(os.listdir(class_path))\n",
    "            \n",
    "            images_by_class[class_index] = []\n",
    "            labels_by_class[class_index] = []\n",
    "            \n",
    "            for img_file in img_files:\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                image = load_img(\n",
    "                    img_path,\n",
    "                    target_size=hyperparameters['img_size'],\n",
    "                    color_mode=hyperparameters['color_mode']\n",
    "                )\n",
    "                image = img_to_array(image) / 255.0\n",
    "                images_by_class[class_index].append(image)\n",
    "                labels_by_class[class_index].append(class_index)\n",
    "\n",
    "    train_images, train_labels = [], []\n",
    "    test_images, test_labels = [], []\n",
    "\n",
    "    print(\"\\nData Distribution:\")\n",
    "    print(f\"{'Class':^10} {'Total':^10} {'Train':^10} {'Test':^10}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    test_size = hyperparameters['test_split_size']\n",
    "    for class_idx in sorted(images_by_class.keys()):\n",
    "        X = np.array(images_by_class[class_idx])\n",
    "        y = np.array(labels_by_class[class_idx])\n",
    "        \n",
    "        total_samples = len(X)\n",
    "        chunk_size = int(total_samples * test_size)\n",
    "        start_idx = split_index * chunk_size\n",
    "        end_idx = start_idx + chunk_size\n",
    "        \n",
    "        test_mask = np.zeros(total_samples, dtype=bool)\n",
    "        test_mask[start_idx:end_idx] = True\n",
    "        \n",
    "        test_images.extend(X[test_mask])\n",
    "        test_labels.extend(y[test_mask])\n",
    "        train_images.extend(X[~test_mask])\n",
    "        train_labels.extend(y[~test_mask])\n",
    "\n",
    "        print(f\"{class_idx:^10} {total_samples:^10} {sum(~test_mask):^10} {sum(test_mask):^10}\")\n",
    "\n",
    "    return np.array(train_images), np.array(train_labels), np.array(test_images), np.array(test_labels)\n",
    "\n",
    "def save_processed_data(data_dir, split_index):\n",
    "    base_name = f\"{data_dir.split('/')[-2]}_{data_dir.split('/')[-1]}_split_{split_index}\"\n",
    "    save_path = os.path.join(DATA_DIR, base_name)\n",
    "\n",
    "    if os.path.exists(f\"{save_path}_train.pkl\"):\n",
    "        print(f\"> Data already saved in {save_path}_train.pkl\")\n",
    "        return\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = load_and_split_data(data_dir, split_index)\n",
    "\n",
    "    with open(f\"{save_path}_train.pkl\", 'wb') as f:\n",
    "        pickle.dump((x_train, y_train), f)\n",
    "    with open(f\"{save_path}_test.pkl\", 'wb') as f:\n",
    "        pickle.dump((x_test, y_test), f)\n",
    "    \n",
    "    print(f\"> Saved processed data to {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "def load_processed_data(base_path):\n",
    "    with open(f\"{base_path}_train.pkl\", 'rb') as f:\n",
    "        x_train, y_train = pickle.load(f)\n",
    "    with open(f\"{base_path}_test.pkl\", 'rb') as f:\n",
    "        x_test, y_test = pickle.load(f)\n",
    "\n",
    "    test_size = hyperparameters['test_split_size']\n",
    "    print(\"\\nSummary of Loaded Data:\")\n",
    "    print(f\"[DATAINFO] Total images: {len(x_train) + len(x_test)}\")\n",
    "    print(f\"[DATAINFO] Training set: {len(x_train)} images ({(1-test_size)*100:.0f}%)\")\n",
    "    print(f\"[DATAINFO] Test set: {len(x_test)} images ({test_size*100:.0f}%)\")\n",
    "    print(f\"[DATAINFO] Image shape: {x_train[0].shape}\")\n",
    "    print()\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 6] - Model Building Functions\n",
    "def build_custom_cnn_model(input_shape=(128, 128, 1), num_classes=4, architecture_name='cnn', fine_tune=True):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    if architecture_name == 'cnn':\n",
    "        # Use the values from the hyperparameters dictionary\n",
    "        x = layers.Conv2D(hyperparameters['cnn_filters'][0], hyperparameters['cnn_kernel_size'], \n",
    "                          activation=hyperparameters['cnn_activation_function'], padding=hyperparameters['cnn_padding'])(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(hyperparameters['cnn_pool_size'])(x)\n",
    "        \n",
    "        x = layers.Conv2D(hyperparameters['cnn_filters'][1], hyperparameters['cnn_kernel_size'], \n",
    "                          activation=hyperparameters['cnn_activation_function'], padding=hyperparameters['cnn_padding'])(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(hyperparameters['cnn_pool_size'])(x)\n",
    "        \n",
    "        x = layers.Conv2D(hyperparameters['cnn_filters'][2], hyperparameters['cnn_kernel_size'], \n",
    "                          activation=hyperparameters['cnn_activation_function'], padding=hyperparameters['cnn_padding'])(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(hyperparameters['cnn_pool_size'])(x)\n",
    "        \n",
    "        x = layers.Conv2D(hyperparameters['cnn_filters'][3], hyperparameters['cnn_kernel_size'], \n",
    "                          activation=hyperparameters['cnn_activation_function'], padding=hyperparameters['cnn_padding'])(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "        x = layers.Dense(hyperparameters['cnn_dense_units'], activation=hyperparameters['cnn_activation_function'])(x)\n",
    "        x = layers.Dropout(hyperparameters['cnn_dropout_rate'])(x)\n",
    "    else:\n",
    "        # Upsample input to the required size if needed (InceptionV3 requires minimum 75x75)\n",
    "        if architecture_name == 'inceptionv3' and (input_shape[0] < 75 or input_shape[1] < 75):\n",
    "            required_size = (75, 75)  # InceptionV3 minimum size\n",
    "        else:\n",
    "            required_size = (input_shape[0], input_shape[1])  # Default size for other models\n",
    "            \n",
    "        x = layers.Resizing(required_size[0], required_size[1])(inputs)  # Resize input to required size\n",
    "\n",
    "        # Convert grayscale (1-channel) to 3-channel RGB for pretrained models\n",
    "        x = layers.Conv2D(3, (1, 1))(x)\n",
    "        \n",
    "        # Pretrained model selection logic\n",
    "        # ResNet Variants\n",
    "        if architecture_name == 'resnet50':\n",
    "            from tensorflow.keras.applications import ResNet50\n",
    "            base_model = ResNet50(weights=hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        elif architecture_name == 'resnet101':\n",
    "            from tensorflow.keras.applications import ResNet101\n",
    "            base_model = ResNet101(hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        elif architecture_name == 'resnet152':\n",
    "            from tensorflow.keras.applications import ResNet152\n",
    "            base_model = ResNet152(weights=hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        \n",
    "        # EfficientNetB0\n",
    "        elif architecture_name == 'efficientnetb0':\n",
    "            from tensorflow.keras.applications import EfficientNetB0\n",
    "            base_model = EfficientNetB0(weights=hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "\n",
    "        # VGGNet Variants\n",
    "        elif architecture_name == 'vgg16':\n",
    "            from tensorflow.keras.applications import VGG16\n",
    "            base_model = VGG16(weights=hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "        elif architecture_name == 'vgg19':\n",
    "            from tensorflow.keras.applications import VGG19\n",
    "            base_model = VGG19(weights=hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "\n",
    "        # InceptionV3\n",
    "        elif architecture_name == 'inceptionv3':\n",
    "            from tensorflow.keras.applications import InceptionV3\n",
    "            base_model = InceptionV3(weights=hyperparameters['pretained_model_weights'], include_top=False, input_shape=(required_size[0], required_size[1], 3))\n",
    "\n",
    "        # U-Net (not from Keras applications, custom U-Net function)\n",
    "        elif architecture_name == 'unet':\n",
    "            base_model = build_unet_model(input_shape=(required_size[0], required_size[1], 3))  # Custom function to build U-Net model\n",
    "\n",
    "        # Set base model to non-trainable if fine-tuning is disabled\n",
    "        if not fine_tune:\n",
    "            base_model.trainable = False\n",
    "        else:\n",
    "            base_model.trainable = True\n",
    "        \n",
    "        # Apply base model to input\n",
    "        x = base_model(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model using learning rate and loss from the hyperparameters\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['learning_rate']),\n",
    "        loss= hyperparameters['cnn_loss_function'],\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 7] - Pretext Task Functions\n",
    "def augment_image(image, rotation_angle):\n",
    "    if rotation_angle == 90:\n",
    "        image = tf.image.rot90(image)\n",
    "    elif rotation_angle == 180:\n",
    "        image = tf.image.rot90(image, k=2)\n",
    "    elif rotation_angle == 270:\n",
    "        image = tf.image.rot90(image, k=3)\n",
    "    \n",
    "    label = rotation_angle // 90\n",
    "    return image, label\n",
    "\n",
    "def preprocess_data(images):\n",
    "    augmented_images = []\n",
    "    labels = []\n",
    "    for image in images:\n",
    "        for rotation_angle in [0, 90, 180, 270]:\n",
    "            aug_image, label = augment_image(image, rotation_angle)\n",
    "            augmented_images.append(aug_image)\n",
    "            labels.append(label)\n",
    "    print(f'> {len(augmented_images)} augmented images generated each of shape {augmented_images[0].shape} with {len(labels)} labels')\n",
    "    return np.array(augmented_images), np.array(labels)\n",
    "\n",
    "def save_model(model, architecture_name, data_path, split_index):\n",
    "    try:\n",
    "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "        model_name = f\"pretext_model_{os.path.basename(data_path)}_{architecture_name}_split_{split_index}.h5\"\n",
    "        model_path = os.path.join(MODEL_DIR, model_name)\n",
    "        \n",
    "        try:\n",
    "            model.save(model_path, save_format='h5')\n",
    "        except Exception as h5_error:\n",
    "            print(f\"> H5 saving failed, trying SavedModel format: {h5_error}\")\n",
    "            model_path = model_path.replace('.h5', '')\n",
    "            model.save(model_path, save_format='tf')\n",
    "            \n",
    "        print(f\"> Model successfully saved at: {model_path}\")\n",
    "        return model_path\n",
    "    except Exception as e:\n",
    "        print(f\"> Error saving model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model(architecture_name, data_path, split_index):\n",
    "    model_name = f\"pretext_model_{os.path.basename(data_path)}_{architecture_name}_split_{split_index}.h5\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_name)\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(model_path):\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "        else:\n",
    "            model_path = model_path.replace('.h5', '')\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"> Model successfully loaded from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"> Error loading model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def run_pretext_pipeline(data_path, architecture_name, split_index):\n",
    "    # set_all_seeds(RANDOM_SEED)\n",
    "    \n",
    "    model_name = f\"pretext_model_{os.path.basename(data_path)}_{architecture_name}_split_{split_index}.h5\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_name)\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"> Alredy exists in {model_path}. No need for training.\")\n",
    "        return\n",
    "\n",
    "    x_train, y_train, _, _ = load_processed_data(data_path)\n",
    "    x_augmented, y_augmented = preprocess_data(x_train)\n",
    "    \n",
    "    model = build_custom_cnn_model(\n",
    "        input_shape=hyperparameters['input_shape'],\n",
    "        num_classes=hyperparameters['num_classes'],\n",
    "        architecture_name=architecture_name,\n",
    "        fine_tune=hyperparameters['fine_tune']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=hyperparameters['early_stopping_patience'],\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=hyperparameters['lr_reduction_factor'],\n",
    "            patience=hyperparameters['lr_reduction_patience']\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    '''Not proceeding with making a static validation set as not quite sure about the stratified nature'''\n",
    "    # validation_size = int(len(x_augmented) * hyperparameters['validation_split'])\n",
    "    # indices = np.arange(len(x_augmented))\n",
    "    # np.random.seed(RANDOM_SEED)\n",
    "    # np.random.shuffle(indices)\n",
    "    # train_idx = indices[validation_size:]\n",
    "    # val_idx = indices[:validation_size]\n",
    "    \n",
    "    # history = model.fit(\n",
    "    #     x_augmented[train_idx], y_augmented[train_idx],\n",
    "    #     validation_data=(x_augmented[val_idx], y_augmented[val_idx]),\n",
    "    #     batch_size=hyperparameters['batch_size'],\n",
    "    #     epochs=hyperparameters['epochs'],\n",
    "    #     callbacks=callbacks,\n",
    "    #     shuffle=False\n",
    "    # )\n",
    "\n",
    "    history = model.fit(\n",
    "        x_augmented, y_augmented,\n",
    "        validation_split = hyperparameters['validation_split'],\n",
    "        batch_size=hyperparameters['batch_size'],\n",
    "        epochs=hyperparameters['epochs'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save the trained model\n",
    "    save_model(model, architecture_name, data_path, split_index)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 8] - Downstream Task Functions\n",
    "def extract_features(pretext_model, x_data, layer_index=-2):\n",
    "    intermediate_model = models.Model(inputs=pretext_model.input, outputs=pretext_model.layers[layer_index].output)\n",
    "    features = intermediate_model.predict(x_data, verbose=2)\n",
    "    print(f'> extracted features of shape {features.shape}')\n",
    "    return features\n",
    "\n",
    "def evaluate_downstream_task(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='macro'),\n",
    "        'recall': recall_score(y_test, y_pred, average='macro'),\n",
    "        'f1': f1_score(y_test, y_pred, average='macro'),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "def train_downstream_task(train_features, train_labels, test_features, test_labels, classifier='random_forest', n_splits=None):\n",
    "    print(f'> Performing downstream task with {classifier}')\n",
    "    \n",
    "    # Assign number of splits from hyperparameters if not specified\n",
    "    if n_splits is None:\n",
    "        n_splits = hyperparameters['cv_splits']\n",
    "    \n",
    "    # Initialize classifier based on hyperparameters\n",
    "    if classifier == 'random_forest':\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=hyperparameters['rf_n_estimators'],\n",
    "            random_state=RANDOM_SEED,\n",
    "            verbose=0\n",
    "        )\n",
    "    elif classifier == 'svm':\n",
    "        clf = SVC(\n",
    "            kernel=hyperparameters['svm_kernel'],\n",
    "            random_state=RANDOM_SEED,\n",
    "            verbose=False\n",
    "        )\n",
    "    elif classifier == 'gradient_boosting':\n",
    "        clf = GradientBoostingClassifier(\n",
    "            n_estimators=hyperparameters['gb_n_estimators'],\n",
    "            random_state=RANDOM_SEED,\n",
    "            verbose=0\n",
    "        )\n",
    "    elif classifier == 'xgboost':\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=hyperparameters['xgb_n_estimators'],\n",
    "            random_state=RANDOM_SEED,\n",
    "            use_label_encoder=False,  # Update for recent versions of XGBoost\n",
    "            verbose=0\n",
    "        )\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    cv_scores = {\n",
    "        'accuracies': [], 'precisions': [], 'recalls': [], 'f1_scores': []\n",
    "    }\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(train_features, train_labels):\n",
    "        X_train_fold, X_val_fold = train_features[train_idx], train_features[val_idx]\n",
    "        y_train_fold, y_val_fold = train_labels[train_idx], train_labels[val_idx]\n",
    "        \n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = clf.predict(X_val_fold)\n",
    "        \n",
    "        # Append cross-validation scores\n",
    "        cv_scores['accuracies'].append(accuracy_score(y_val_fold, y_pred))\n",
    "        cv_scores['precisions'].append(precision_score(y_val_fold, y_pred, average='macro'))\n",
    "        cv_scores['recalls'].append(recall_score(y_val_fold, y_pred, average='macro'))\n",
    "        cv_scores['f1_scores'].append(f1_score(y_val_fold, y_pred, average='macro'))\n",
    "    \n",
    "    # Train final classifier on full training data and evaluate on test data\n",
    "    clf.fit(train_features, train_labels)\n",
    "    test_metrics = evaluate_downstream_task(clf, test_features, test_labels)\n",
    "    \n",
    "    return clf, cv_scores, test_metrics\n",
    "\n",
    "def run_downstream_pipeline(data_path, architecture_name, downstream_classifier, split_index):\n",
    "    x_train, y_train, x_test, y_test = load_processed_data(data_path)\n",
    "    pretext_model = load_model(architecture_name, data_path, split_index)\n",
    "    \n",
    "    train_features = extract_features(pretext_model, x_train, hyperparameters['feature_extraction_layer'])\n",
    "    test_features = extract_features(pretext_model, x_test, hyperparameters['feature_extraction_layer'])\n",
    "    \n",
    "    clf, cv_scores, test_metrics = train_downstream_task(\n",
    "        train_features, y_train,\n",
    "        test_features, y_test,\n",
    "        classifier=downstream_classifier,\n",
    "        n_splits=hyperparameters['cv_splits']\n",
    "    )\n",
    "    \n",
    "    return clf, cv_scores, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 10] - Main Execution\n",
    "def main():\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "    # Check for GPU\n",
    "    print(\"> GPU Availability: \", tf.config.list_physical_devices('GPU'))\n",
    "    \n",
    "    # Parameters\n",
    "    mode = experiment_parameters['mode']\n",
    "    split_index = experiment_parameters['split_index']\n",
    "    architecture = experiment_parameters['architecture']\n",
    "    classifier = experiment_parameters['classifier']\n",
    "    \n",
    "    # Data directory\n",
    "    data_dir = experiment_parameters['data_dir']\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Process and save data\n",
    "        if mode in ['process', 'all']:\n",
    "            print(\"\\n=== Processing Data ===\")\n",
    "            data_path = save_processed_data(data_dir, split_index)\n",
    "        \n",
    "        # Step 2: Train pretext model\n",
    "        if mode in ['pretext', 'all']:\n",
    "            print(\"\\n=== Training Pretext Model ===\")\n",
    "            data_path = os.path.join(DATA_DIR, f\"{data_dir.split('/')[-2]}_{data_dir.split('/')[-1]}_split_{split_index}\")\n",
    "            \n",
    "            # TODO, load the data here\n",
    "\n",
    "            architectures = architecture_list if architecture == 'all' else [architecture]\n",
    "            for arch in architectures:\n",
    "                print(f\">> Training architecture: {arch}\")\n",
    "                history = run_pretext_pipeline(data_path, arch, split_index)\n",
    "\n",
    "            # TODO, destroy data memory here\n",
    "        \n",
    "        # Step 3: Run downstream task\n",
    "        if mode in ['downstream', 'all']:\n",
    "            print(\"\\n=== Running Downstream Task ===\")\n",
    "            data_path = os.path.join(DATA_DIR, f\"{data_dir.split('/')[-2]}_{data_dir.split('/')[-1]}_split_{split_index}\")\n",
    "            # TODO, load the data here\n",
    "            \n",
    "            results_tracker = ResultsTracker()\n",
    "            architectures = architecture_list if architecture == 'all' else [architecture]\n",
    "            classifiers = classifier_list if classifier == 'all' else [classifier]\n",
    "            \n",
    "            for arch in architectures:\n",
    "                # TODO, Load the architecture here\n",
    "                for clf in classifiers:\n",
    "                    print(f\">> Evaluating classifier: {clf} with architecture: {arch}\")\n",
    "                    classifier_model, cv_scores, test_metrics = run_downstream_pipeline(\n",
    "                        data_path, arch, clf, split_index\n",
    "                    )\n",
    "                    \n",
    "                    results_tracker.add_result(\n",
    "                        data_dir=data_dir,\n",
    "                        architecture=arch,\n",
    "                        classifier=clf,\n",
    "                        cv_metrics=cv_scores,\n",
    "                        test_metrics=test_metrics\n",
    "                    )\n",
    "                results_tracker.display_results()\n",
    "                # TODO, destroy architecture memory here\n",
    "\n",
    "            # TODO, destroy data memory here\n",
    "\n",
    "            results_tracker.display_results()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError occurred: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:12:10] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:14:14] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:16:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:18:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:20:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/siam/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [15:22:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# [Cell 11] - Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d-%Hh%Mm%Ss')\n",
    "    filename = os.path.join(RESULTS_DIR, f\"{timestamp}-dir_{experiment_parameters['data_dir'].split('/')[-2]}_{experiment_parameters['data_dir'].split('/')[-1]}-mode_{experiment_parameters['mode']}-split_{experiment_parameters['split_index']}-arch_{experiment_parameters['architecture']}-clf_{experiment_parameters['classifier']}.txt\")\n",
    "    print(f\"> Output is being saved on {filename}\")\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'w') as output_file:\n",
    "            sys.stdout = output_file\n",
    "            display_configurations()\n",
    "            main()\n",
    "            sys.stdout = sys.__stdout__\n",
    "    except Exception as e:\n",
    "        sys.stdout = sys.__stdout__\n",
    "        print(\"ERROR OCCURED\", e)\n",
    "        \n",
    "    print(\"Process finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
