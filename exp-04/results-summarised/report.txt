===============================================================================
                QPM MILITARY VEHICLE CLASSIFICATION PROJECT
-------------------------------------------------------------------------------
Project: Quantum Phase Microscopy (QPM) Military Vehicle Classification
Dataset: Satellite imagery of military vehicles
Analysis Period: Multiple splits analysis
===============================================================================

PROJECT OVERVIEW
===============================================================================

# Dataset Characteristics:
---------------------------
Input Specifications:
- Image size: 128x128 pixels
- Color mode: Grayscale
- Total images: 1345
- Training set: 1082 images (80%)
- Test set: 263 images (20%)

Class Distribution:
Vehicle Type    Total Images    Training    Testing
--------------  -------------   ---------   -------
2s1             174            140          34
bmp2            107             86          21
btr70            92             74          18
m1              129            104          25
m2              128            103          25
m35             129            104          25
m548            128            103          25
m60             176            141          35
t72             108             87          21
zsu23           174            140          34

# Technical Environment:
-------------------------
Hardware:
- GPU: NVIDIA GeForce
- CUDA Version: 11.8
- Driver Version: 522.06
- Memory: 24576MiB

Software Versions:
Library          Curr Version
--------------   ---------   
Python           3.10.15     
TensorFlow       2.9.1       
NumPy            1.22.0      
Pandas           1.4.0       
Scikit-learn     1.5.2       
XGBoost          2.1.2       
Matplotlib       3.8.4       
Pillow           11.0.0      

# EXPERIMENTAL SETUP
===============================================================================
2.1 Architectures Tested:
-------------------------
A. Deep Learning Models:
   1. CNN (Custom Implementation)
      - Filters: [32, 64, 128, 256]
      - Kernel size: (3, 3)
      - Pooling: (2, 2)
      - Dense units: 512
      - Dropout rate: 0.5

   2. ResNet Variants
      - ResNet50
      - ResNet101
      - ResNet152
      Base configuration:
      - Input shape: (128, 128, 1)
      - Pretrained: ImageNet
      - Fine-tuned: True

   3. EfficientNetB0
      - Input shape: (128, 128, 1)
      - Pretrained: ImageNet
      - Fine-tuned: True

   4. VGG Variants
      - VGG16
      - VGG19
      Base configuration:
      - Input shape: (128, 128, 1)
      - Pretrained: ImageNet
      - Fine-tuned: True

   5. InceptionV3
      - Input shape: (128, 128, 1)
      - Pretrained: ImageNet
      - Fine-tuned: True

   6. U-Net
      - Input shape: (128, 128, 1)
      - Custom implementation

# Classifiers:
---------------
1. Random Forest
   - n_estimators: 100
   - Feature extraction: layer -2

2. SVM
   - Kernel: linear
   - Feature extraction: layer -2

3. Gradient Boosting
   - n_estimators: 100
   - Feature extraction: layer -2

4. XGBoost
   - n_estimators: 100
   - Feature extraction: layer -2

# Training Configuration:
--------------------------
Common Parameters:
- Batch size: 32
- Learning rate: 0.001
- Validation split: 0.25
- Early stopping patience: 3
- LR reduction patience: 3
- LR reduction factor: 0.5
- Cross-validation splits: 5

PERFORMANCE ANALYSIS BY ARCHITECTURE AND CLASSIFIER
===============================================================================
# Detailed Performance Tables
-----------------------------
=== CNN Architecture ===
Classifier    Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest  Accuracy    57.8%    71.5%    59.7%    74.1%    66.5%    65.9±6.8%
              Precision   56.1%    74.4%    61.4%    74.4%    67.0%    66.7±7.8%
              Recall      55.3%    73.2%    57.3%    73.2%    64.1%    64.6±8.2%
              F1-Score    52.5%    72.7%    58.1%    72.7%    63.8%    64.0±9.0%

SVM           Accuracy    35.0%    35.4%    35.4%    33.1%    39.2%    35.6±2.2%
              Precision   18.8%    18.9%    25.5%    18.9%    23.2%    21.1±3.1%
              Recall      29.8%    31.8%    31.8%    30.3%    34.2%    31.6±1.6%
              F1-Score    22.7%    25.8%    25.8%    22.1%    26.3%    24.5±1.9%

GradBoost     Accuracy    60.1%    72.6%    70.7%    74.5%    71.5%    69.9±5.6%
              Precision   59.1%    73.5%    70.9%    73.8%    73.8%    70.2±6.2%
              Recall      58.0%    71.5%    68.1%    69.5%    69.5%    67.3±5.3%
              F1-Score    55.5%    71.2%    68.4%    69.8%    69.8%    66.9±6.3%

XGBoost       Accuracy    62.4%    76.4%    71.1%    77.9%    72.6%    72.1±6.1%
              Precision   61.3%    77.1%    74.3%    77.6%    74.3%    72.9±6.6%
              Recall      60.0%    75.6%    70.1%    76.4%    70.1%    70.4±6.6%
              F1-Score    57.5%    75.0%    69.2%    76.1%    70.5%    69.7±7.3%

=== EfficientNetB0 Architecture ===
Classifier    Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest  Accuracy    49.0%    68.8%    61.2%    81.0%    61.2%    64.2±11.8%
              Precision   46.8%    69.3%    62.9%    80.3%    62.9%    64.4±12.3%
              Recall      47.7%    66.4%    58.4%    80.3%    58.4%    62.2±12.2%
              F1-Score    46.0%    66.9%    58.6%    79.0%    58.6%    61.8±12.1%

SVM           Accuracy    44.1%    81.4%    44.1%    93.2%    44.1%    61.4±24.0%
              Precision   38.7%    82.1%    38.5%    92.9%    38.5%    58.1±26.5%
              Recall      41.9%    81.0%    37.6%    93.1%    37.6%    58.2±26.7%
              F1-Score    39.9%    80.2%    32.3%    92.7%    32.3%    55.5±28.8%

GradBoost     Accuracy    49.4%    73.0%    70.0%    83.7%    70.0%    69.2±12.5%
              Precision   47.5%    74.2%    70.0%    83.0%    70.0%    69.0±13.0%
              Recall      48.1%    71.5%    66.7%    83.0%    66.7%    67.2±12.7%
              F1-Score    46.5%    71.1%    67.1%    82.3%    67.1%    66.8±13.0%

XGBoost       Accuracy    47.9%    74.5%    74.5%    84.0%    74.5%    71.1±13.3%
              Precision   44.1%    74.9%    74.7%    84.2%    74.7%    70.5±15.2%
              Recall      46.2%    72.3%    72.3%    83.6%    72.3%    69.3±13.8%
              F1-Score    44.0%    72.6%    72.6%    82.8%    72.6%    68.9±14.7%

=== InceptionV3 Architecture ===
Classifier   Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    67.7%    81.4%    76.8%    76.8%    62.7%    73.1±7.6%
             Precision   65.5%    82.7%    73.7%    73.7%    63.3%    71.8±7.5%
             Recall      64.6%    80.0%    70.8%    70.8%    62.1%    69.7±6.9%
             F1-Score    63.4%    79.9%    70.0%    70.0%    60.5%    68.8±7.6%

SVM          Accuracy    89.0%    67.3%    82.5%    79.5%    82.5%    80.2±8.1%
             Precision   90.3%    73.7%    82.1%    81.5%    82.1%    81.9±6.0%
             Recall      88.4%    63.6%    81.0%    80.2%    81.0%    78.8±9.3%
             F1-Score    89.0%    61.0%    80.2%    80.0%    80.2%    78.1±10.5%

GradBoost    Accuracy    72.2%    88.6%    77.6%    77.6%    76.4%    78.5±6.2%
             Precision   74.1%    89.0%    77.5%    77.5%    77.5%    79.1±5.8%
             Recall      69.9%    88.1%    76.6%    76.6%    76.6%    77.6±6.7%
             F1-Score    70.6%    88.3%    75.5%    75.5%    75.5%    77.1±6.8%

XGBoost      Accuracy    76.4%    88.2%    76.0%    77.6%    76.0%    78.8±5.2%
             Precision   77.8%    88.2%    74.7%    77.9%    76.1%    78.9±5.3%
             Recall      74.6%    87.9%    72.3%    75.6%    75.6%    77.2±6.1%
             F1-Score    75.2%    87.7%    72.6%    74.4%    74.4%    76.9±6.1%

=== ResNet50 Architecture ===
Classifier   Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    71.1%    74.9%    59.7%    74.9%    74.9%    71.1±6.5%
             Precision   73.7%    75.7%    53.2%    75.7%    75.7%    70.8±9.7%
             Recall      68.4%    75.0%    50.3%    75.0%    75.0%    68.7±10.7%
             F1-Score    68.2%    75.0%    49.9%    75.0%    75.0%    68.6±11.0%

SVM          Accuracy    76.0%    44.9%    36.1%    44.9%    44.9%    49.4±15.6%
             Precision   76.6%    37.6%    21.7%    37.6%    37.6%    42.2±20.8%
             Recall      73.7%    38.7%    30.9%    38.7%    38.7%    44.1±16.9%
             F1-Score    74.3%    31.2%    24.4%    31.2%    31.2%    38.5±19.6%

GradBoost    Accuracy    75.7%    71.1%    64.3%    71.1%    71.1%    70.7±4.1%
             Precision   81.9%    72.5%    65.7%    72.5%    72.5%    73.0±5.8%
             Recall      74.7%    71.5%    63.7%    71.5%    71.5%    70.6±4.3%
             F1-Score    75.9%    71.2%    63.6%    71.2%    71.2%    70.6±4.5%

XGBoost      Accuracy    77.2%    68.4%    65.4%    68.4%    68.4%    69.6±4.3%
             Precision   80.9%    68.7%    67.3%    68.7%    68.7%    70.9±5.5%
             Recall      75.7%    69.0%    65.2%    69.0%    69.0%    69.6±3.8%
             F1-Score    76.4%    68.3%    65.4%    68.3%    68.3%    69.3±4.1%

=== ResNet101 Architecture ===
Classifier   Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    47.5%    68.4%    79.5%    47.5%    79.5%    64.5±15.8%
             Precision   51.7%    70.3%    80.9%    51.7%    80.9%    67.1±14.7%
             Recall      46.9%    67.7%    78.4%    46.9%    78.4%    63.7±15.6%
             F1-Score    45.8%    66.9%    78.6%    45.8%    78.6%    63.1±16.2%

SVM          Accuracy    45.6%    16.7%    13.3%    13.3%    13.3%    20.4±14.2%
             Precision   54.5%    3.2%     1.4%     1.4%     1.4%     12.4±23.5%
             Recall      44.8%    12.6%    10.0%    10.0%    10.0%    17.5±15.5%
             F1-Score    44.1%    4.8%     2.5%     2.5%     2.5%     11.3±18.5%

GradBoost    Accuracy    53.6%    72.6%    81.4%    53.6%    81.4%    68.5±13.8%
             Precision   60.5%    73.4%    80.9%    60.5%    80.9%    71.2±10.1%
             Recall      52.6%    72.5%    80.2%    52.6%    80.2%    67.6±13.9%
             F1-Score    53.6%    72.1%    79.8%    53.6%    79.8%    67.8±13.2%

XGBoost      Accuracy    52.5%    70.3%    81.7%    52.5%    81.7%    67.7±14.2%
             Precision   58.7%    70.7%    81.7%    58.7%    81.7%    70.3±11.3%
             Recall      51.8%    69.4%    80.7%    51.8%    80.7%    66.9±14.4%
             F1-Score    52.4%    69.0%    80.1%    52.4%    80.1%    66.8±13.8%

=== ResNet152 Architecture ===
Classifier    Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    71.5%    65.8%    76.8%    76.8%    38.4%    65.9±15.8%
             Precision   70.1%    67.9%    73.7%    73.7%    32.5%    63.6±17.2%
             Recall      70.7%    63.5%    73.2%    73.2%    35.7%    63.3±15.9%
             F1-Score    70.0%    62.5%    72.7%    72.7%    33.5%    62.3±16.6%

SVM          Accuracy    13.3%    53.6%    13.3%    13.3%    26.2%    24.0±17.5%
             Precision   1.3%     50.7%    1.3%     1.3%     10.3%    13.0±21.5%
             Recall      10.0%    51.2%    10.0%    10.0%    20.3%    20.3±18.2%
             F1-Score    2.3%     45.3%    2.3%     2.3%     12.3%    12.9±18.8%

GradBoost    Accuracy    76.0%    67.3%    83.7%    67.3%    40.3%    66.9±15.9%
             Precision   78.0%    68.7%    82.8%    68.7%    39.2%    67.5±16.5%
             Recall      75.4%    64.8%    80.4%    64.8%    37.8%    64.6±15.9%
             F1-Score    76.0%    64.8%    80.7%    64.8%    36.0%    64.5±16.8%

XGBoost      Accuracy    78.3%    69.6%    84.4%    69.6%    37.6%    67.9±17.8%
             Precision   78.3%    70.8%    84.0%    70.8%    37.7%    68.3±17.6%
             Recall      77.2%    66.8%    81.7%    66.8%    35.8%    65.7±17.4%
             F1-Score    77.3%    67.2%    81.8%    67.2%    34.6%    65.6±17.8%

=== VGG16 Architecture ===
Classifier    Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    13.3%    13.3%    13.3%    13.3%    56.3%    21.9±19.2%
             Precision   1.3%     1.3%     1.3%     1.3%     55.7%    12.2±24.3%
             Recall      10.0%    10.0%    10.0%    10.0%    53.8%    18.8±19.6%
             F1-Score    2.3%     2.3%     2.3%     2.3%     53.6%    12.6±22.9%

SVM          Accuracy    13.3%    13.3%    13.3%    13.3%    13.3%    13.3±0.0%
             Precision   1.3%     1.3%     1.3%     1.3%     1.3%     1.3±0.0%
             Recall      10.0%    10.0%    10.0%    10.0%    10.0%    10.0±0.0%
             F1-Score    2.3%     2.3%     2.3%     2.3%     2.3%     2.3±0.0%

GradBoost    Accuracy    13.3%    13.3%    13.3%    13.3%    51.7%    21.0±17.2%
             Precision   1.3%     1.3%     1.3%     1.3%     50.2%    11.1±21.8%
             Recall      10.0%    10.0%    10.0%    10.0%    49.3%    17.9±17.6%
             F1-Score    2.3%     2.3%     2.3%     2.3%     49.0%    11.6±20.9%

XGBoost      Accuracy    13.3%    13.3%    13.3%    13.3%    52.5%    21.1±17.5%
             Precision   1.3%     1.3%     1.3%     1.3%     50.6%    11.2±22.0%
             Recall      10.0%    10.0%    10.0%    10.0%    49.9%    18.0±17.8%
             F1-Score    2.3%     2.3%     2.3%     2.3%     49.7%    11.8±21.2%

=== VGG19 Architecture ===
Classifier   Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    51.3%    70.0%    13.3%    65.4%    65.4%    53.1±23.3%
             Precision   48.0%    67.5%    1.3%     64.3%    64.3%    49.1±27.2%
             Recall      49.0%    67.4%    10.0%    62.6%    62.6%    50.3±23.4%
             F1-Score    47.7%    66.2%    2.3%     60.8%    60.8%    47.6±26.4%

SVM          Accuracy    32.3%    13.3%    13.3%    13.3%    13.3%    17.1±8.5%
             Precision   13.6%    1.3%     1.3%     1.3%     1.3%     3.8±5.5%
             Recall      24.7%    10.0%    10.0%    10.0%    10.0%    12.9±6.5%
             F1-Score    16.4%    2.3%     2.3%     2.3%     2.3%     5.1±6.3%

GradBoost    Accuracy    49.0%    73.0%    13.3%    69.6%    69.6%    54.9±25.0%
             Precision   47.7%    71.8%    1.3%     68.1%    68.1%    51.4±28.6%
             Recall      45.8%    71.2%    10.0%    67.2%    67.2%    52.3±25.3%
             F1-Score    44.9%    70.7%    2.3%     66.1%    66.1%    50.0±28.2%

XGBoost      Accuracy    48.7%    77.9%    13.3%    68.1%    68.1%    55.2±25.4%
             Precision   46.6%    78.1%    1.3%     67.0%    67.0%    52.0±30.1%
             Recall      45.5%    77.2%    10.0%    65.7%    65.7%    52.8±26.3%
             F1-Score    45.1%    76.3%    2.3%     64.7%    64.7%    50.6±29.6%

=== UNet Architecture ===
Classifier   Metric      Split0   Split1   Split2   Split3   Split4   Avg±StdDev
--------------------------------------------------------------------------------
RandomForest Accuracy    37.3%    35.7%    30.4%    35.7%    30.4%    33.9±3.3%
             Precision   34.6%    35.1%    33.1%    35.1%    33.1%    34.2±1.0%
             Recall      36.4%    36.4%    29.2%    36.4%    29.2%    33.5±3.9%
             F1-Score    35.1%    34.9%    30.1%    34.9%    30.1%    33.0±2.7%

SVM          Accuracy    13.3%    13.3%    13.3%    13.3%    13.3%    13.3±0.0%
             Precision   1.3%     1.3%     1.3%     1.3%     1.3%     1.3±0.0%
             Recall      10.0%    10.0%    10.0%    10.0%    10.0%    10.0±0.0%
             F1-Score    2.3%     2.3%     2.3%     2.3%     2.3%     2.3±0.0%

GradBoost    Accuracy    39.9%    35.7%    34.6%    35.7%    34.6%    36.1±2.2%
             Precision   36.4%    34.4%    35.9%    34.4%    35.9%    35.4±0.9%
             Recall      38.2%    35.9%    33.0%    35.9%    33.0%    35.2±2.2%
             F1-Score    36.5%    34.3%    33.7%    34.3%    33.7%    34.5±1.1%

XGBoost      Accuracy    38.4%    33.5%    28.5%    33.5%    28.5%    32.5±4.2%
             Precision   33.9%    34.5%    29.6%    34.5%    29.6%    32.4±2.5%
             Recall      36.1%    34.5%    26.9%    34.5%    26.9%    31.8±4.4%
             F1-Score    34.7%    33.2%    27.7%    33.2%    27.7%    31.3±3.3%

### Top Performing Combinations:

+-----+----------------+-------------+-------------+--------+-------------+
| Rank| Architecture   | Classifier  | Avg Acc (%) | StdDev | Peak Acc (%)|
+-----+----------------+-------------+-------------+--------+-------------+
|   1 | InceptionV3    | SVM         | 80.2        | 8.1    | 89.0        |
|   2 | InceptionV3    | XGBoost     | 78.8        | 5.2    | 88.2        |
|   3 | InceptionV3    | GradBoost   | 78.5        | 6.2    | 88.6        |
|   4 | CNN            | GradBoost   | 69.9        | 5.6    | 74.5        |
|   5 | ResNet50       | XGBoost     | 69.6        | 4.3    | 77.2        |
|   6 | EfficientNetB0 | SVM         | 61.4        | 24.0   | 93.2        |
+-----+----------------+-------------+-------------+--------+-------------+

                           # Best Recognized Vehicle Classes
                           ----------------------------------------------------
                           Architecture    Class     Accuracy    Consistency
                           InceptionV3     M1        89.2%      ±4.2%
                           InceptionV3     T72       87.8%      ±3.8%
                           EfficientNetB0  ZSU23     86.4%      ±4.5%

                           # Most Challenging Classes
UNVERIFIED                 -----------------------------------------------------
                           Architecture    Class     Accuracy    Consistency
                           All             BTR70     71.2%      ±8.9%
                           All             BMP2      73.5%      ±7.6%
                           All             2S1       75.8%      ±6.8%

                           # Training Time vs Accuracy Trade-off
                           -----------------------------------------------------
                           Architecture    Train Time(s)  Accuracy  Efficiency Ratio
                           InceptionV3    47.8          78.8%     1.65
                           EfficientNetB0 31.3          71.1%     2.27
                           ResNet50       44.4          69.6%     1.57
                           CNN            7.5           72.1%     9.61

###

# Architecture Stability:
- Most Stable: InceptionV3 (variance typically <7%)
- Least Stable: VGG16/19 (variance >20%) + Does not converge
- ResNet family shows split-dependent performance (15-17% variance)

# Classifier Patterns:
- XGBoost/GradBoost generally outperform RandomForest
- SVM shows extreme variance (excellent or poor, rarely middle)
- RandomForest provides moderate but stable performance

# Critical Issues:
- VGG architectures fail completely on some splits (13.3% accuracy)
- UNet consistently underperforms (<40% accuracy)
- High variance between splits suggests data sensitivity

# Metric Correlations:
- Strong correlation between accuracy and F1-score
- Precision typically higher than recall
- Performance gaps between validation/test suggest overfitting

###

For maximum accuracy: InceptionV3 + SVM
For stability: InceptionV3 + XGBoost
For resource efficiency: EfficientNetB0 + GradBoost
For quick deployment: CNN + XGBoost

InceptionV3 + SVM on Split 3 shows:
Class 3 (m1) gets misclassified as Class 7 (m60) 4 times
Class 4 (m2) gets misclassified as Class 0 (2s1) and Class 5 (m35) once each
Class 5 (m35) gets misclassified as Class 0 (2s1) twice and Class 3 (m1) twice

Most Common Confusions:
Between m1, m2, m35, m60 classes
2s1 gets confused with m2 and m35
bmp2 and btr70 are sometimes confused
t72 is occasionally misclassified as m1 or m2

RECOMMENDATIONS (SCRATCH)

> Balance class representation in training data / use weighted loss function
> Analyze feature importance for distinguishing m1, m2, m35, m60
> Use mixed precision training if supported by hardware | Parallelize data loading and augmentation  
> Optimize batch size based on GPU memory / Dynamic Batch Size
> Consider model compression techniques like quantization and pruning

> a) Rotation Augmentation:
   - Random rotations (0-360 degrees)
   - Military vehicles can be oriented in any direction
   - Helps model become orientation-invariant
b) Scale Variations:
   - Random scaling (±20%)
   - Accounts for different satellite altitudes
   - Simulates varying image resolutions
c) Atmospheric Effects:
   - Add gaussian noise
   - Blur variations
      > Median Blur: Effective for reducing salt-and-pepper noise 
      (a type of image noise that appears as white and black pixels randomly scattered throughout an image)
   - Contrast/brightness adjustments
   - Simulates different atmospheric conditions
d) Shadow Augmentation:
   > shadow augmentation paper: https://www.asprs.org/wp-content/uploads/pers/2005journal/feb/2005_feb_169-177.pdf
   - Add synthetic shadows
   - Vary shadow directions
   - Important for satellite imagery interpretation
> Architecture Improvements: 
a) Multi-Scale Processing:
   - Add parallel paths processing different scales
   - Combine InceptionV3 with spatial pyramid pooling
      > Spatial Pyramid Pooling (SPP) is a pooling layer that removes the fixed-size constraint of the network, 
      i.e. a CNN does not require a fixed-size input image. 
      Specifically, we add an SPP layer on top of the last convolutional layer. 
      The SPP layer pools the features and generates fixed-length outputs, 
      which are then fed into the fully-connected layers (or other classifiers). 
      In other words, we perform some information aggregation at a deeper stage of the network hierarchy 
      (between convolutional layers and fully-connected layers) to avoid the need for cropping or warping at the beginning.
   - Help capture both fine details and overall vehicle shape
b) Attention Mechanisms:
   - Add spatial attention to focus on vehicle features
   - Channel attention to emphasize important feature maps
   - Especially useful for distinguishing similar vehicles
c) Custom Architecture:
   - Combine best elements of InceptionV3 and EfficientNetB0
   - Add skip connections for better feature preservation
   - Optimize for satellite imagery specifically

> Training Strategy Improvements:
a) Two-Stage Training:
   Stage 1: Coarse classification
   - Vehicle type (tank, truck, artillery)
   Stage 2: Fine-grained classification
   - Specific vehicle model

b) Curriculum Learning:
   1. Start with easily distinguishable classes (significantly different from one another)
   2. Gradually introduce similar vehicles
   3. Finally train on full dataset

c) Loss Function Modifications:
   - Use focal loss to handle class imbalance > addresses class imbalance by focusing more on hard-to-classify examples and less on easy ones
   - Add triplet loss for similar vehicle discrimination
      - The distance between an anchor and a positive (same class) is minimized.
      - The distance between an anchor and a negative (different class) is maximized.
   - Implement angular margin loss for better separation
      - enforces better separation between classes by adding a margin to the angle between feature vectors and class prototypes
   - combining loss functions

# Feature Engineering:
   - Edge detection for vehicle silhouettes
   - Multi-resolution analysis 
      - Early layers capture low-level features (e.g., edges, textures), Deeper layers capture high-level, abstract features (e.g., overall object structure)
         Ways to incorporate:
         - Multi-scale pooling: Use different pooling sizes to aggregate information at various scales.
         - Dilated convolutions: Capture larger receptive fields without losing resolution.
         - Feature pyramids: Combine features from different layers.

# Ensemble Strategies:
a) Model Ensemble:
   - Weighted voting based on model confidence

b) Feature Ensemble:
   - Combine deep(er) features from different architectures
   - Use stacked generalization (stacking prediction/features from different models and feeding them to a new meta-model)

# Domain-Specific Preprocessing:
a) Image Enhancement:
   - Adaptive histogram equalization 
      - enhance the contrast of an image ->  works locally by dividing the image into smaller regions (or tiles) and equalizing the histogram of each region independently
   - Edge enhancement
   - Shadow removal
   - Background removal
   - Classification on isolated vehicles

# Model Interpretability and Refinement:
a) Analysis Tools:
   - Grad-CAM visualization
      - Grad-CAM (Gradient-weighted Class Activation Mapping) is a visualization technique used to highlight the regions of an image that are most relevant for a model's decision. 
      - It generates heatmaps by computing the gradients of the target class score concerning the feature maps of a convolutional layer.
   - Feature importance analysis
   - use techniques like t-SNE or PCA to visualize the extracted features and understand their separability

# Confidence Thresholding:
   - High confidence for critical classifications
   - Allow "unknown" classification
   - Multiple class possibilities with probabilities

Purpose: Understand what features/patterns each architecture learns and which are most crucial for classification.
Methods to Analyze:
a) Visualization Techniques:
   - Grad-CAM (Gradient-weighted Class Activation Mapping)
   - Visualizes which parts of image model focuses on
   - Compare across different architectures
   Example Output:
   - InceptionV3 might focus on vehicle edges
   - ResNet might focus on internal details
   - EfficientNet might look at overall shape

b) Feature Map Analysis:
   - Extract intermediate layer activations
   - Compare activation patterns across models
   - Identify which features are consistently important
   Example:
   Layer 1: Edge detection
   Layer 2: Shape patterns
   Layer 3: Vehicle-specific features

c) Saliency Maps:
   - Show which pixels contribute most to classification
   - Compare across different successful/failed cases
   - Identify common patterns in correct classifications

Hyperparameter Tuning:
# Tune learning rates, tree depths, and regularization parameters for better generalization.
# Perform hyperparameter tuning for XGBoost and GradBoost on InceptionV3 and ResNet50 to further optimize results.

>>> Explore Semi-Supervised Learning
Incorporate semi-supervised learning (SSL) techniques for improving performance, especially for architectures with higher variability.
Techniques like pseudo-labeling or self-training could enhance performance on low-performing splits.

# ROC curves

# Combine predictions from the top-performing classifiers

# BM3D

# using contrastive learning methods like SimCLR or BYOL for feature extraction (have shown great results in self-supervised learning)
   - Contrastive learning methods like SimCLR and BYOL have gained prominence for learning high-quality, 
   generalizable feature representations without requiring labeled data.
    These methods leverage self-supervised learning to train models to extract meaningful features 
    that can later be used for downstream tasks like classification, segmentation, or retrieval.
   - SimCLR learns feature representations by maximizing agreement between different augmented views of the same image and contrasting them with views of other images. 
   It employs a contrastive loss function, such as the Normalized Temperature-Scaled Cross-Entropy Loss (NT-Xent) 

# Vision Transformer Architectures  

// Some codes at https://claude.ai/chat/a4b8f80a-569a-41a2-a613-0bce07559517, https://chatgpt.com/c/673e582f-689c-8013-8399-7d80c1dad692 

/ SORTED OUT RECOMMENDATIONS */
   Dataloading:
      1. To handle class imbalance, data will be truncated to the number of samples of the smallest class
      2. If there are more data in a larger class, data will be chosen randomly
      or, the data will be chosen from the first part (options will be available to configure pipeline)
   Data Augmentation:
      1. Rotation: (0, 90, 180, 270) // 0 is the original image
      2. Very Little Guassian Blur
      3. Shadow Augmentation
      4. BM3D Denoising
      or, 
      BM3D Denoising for all the images then apply (1), (2), (3)
      (options will be available to configure pipeline)
      ---
   Pretext Task:
      1. CNN [Changes: Relu->Leaky Relu | Avg Pooling -> Max Pooling | squeeze and excitation]
      2. Add Vision Transformer Based Architectures: https://www.youtube.com/watch?v=nTlLAS7N7qE&list=PLv8Cp2NvcY8DLQc0vBk7JS3FpX6dgNKWI&index=1
      3. Loss Function Modifications:
         - Add triplet loss for similar vehicle discrimination
            - The distance between an anchor and a positive (same class) is minimized.
            - The distance between an anchor and a negative (different class) is maximized.
         - Implement angular margin loss for better separation
            - enforces better separation between classes by adding a margin to the angle between feature vectors and class prototypes
         - combining loss functions
   Downstream Task:
      1. Should be able to use features from any layer of the Pretext architecture
   Results:
      1. The result log should be more concise without losing any data it is currently printing.
      2. Should add the ROC curves and training curves. (Since we are now using text file to keep the outputs, what should be the best way to prepare the results then? We cannot use jupyter notebook outputs since the notebook outputs under the cell are not being saved correctly, as we will run the code in a remote command line server)

   Apply this recommendations to the current code pipeline. Keep the code self explanatory with appropriate and adequete comments.
